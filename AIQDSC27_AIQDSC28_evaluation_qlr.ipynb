{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIQDSC27 - Machine Learning Algorithms\n",
    "\n",
    "**Student**: Quentin Le Roux\n",
    "\n",
    "## Instructions\n",
    "\n",
    "With the available part of the MIMICS dataset, **propose the best model** (among Linear Regression, KNN, Naive Bayes, RandomForest) to predict:\n",
    "\n",
    "> **re-hospitalization** (evaluation metrics, accuracy)\n",
    "\n",
    "To build the features (X), all or part of the following columns can be used (all types of pre-processing is allowed):\n",
    "\n",
    "- **DOB**: Date of Birth\n",
    "- **GENDER**\n",
    "- **MARITAL_STATUS**\n",
    "- **ETHNICITY**\n",
    "- **INSURANCE**\n",
    "- **DEATHTIME**: Date of Death (if the patient has died)\n",
    "- **ADMITTIME**: Date of the admission\n",
    "- **ADMISSION_TYPE**\n",
    "    - blood, circulatory, congenital, digestive, endocrine, genitourinary, infectious, injury, mental, misc, muscular, neoplasms, nervous, pregnancy, prenatal, respiratory, skin\n",
    "    - Bag of Words representation of diagnosis\n",
    "- **DISCHTIME**: date of the discharge\n",
    "- **DISCHARGE_LOCATION**: patient's destination after discharge from hospital\n",
    "- **TEXT**: discharge medical report\n",
    "- **DAYS_NEXT_ADMIT**: number of days between discharge and readmission\n",
    "- **NXT_ADMITTIME**: date of readmission\n",
    "- **OUTPUT_LABEL**\n",
    "- **DEATHTIME**: Date of Death (if the patient has died)\n",
    "\n",
    "**Data leakage** (i.e. https://www.kaggle.com/alexisbcook/data-leakage) has to be accounted for/dealt with.\n",
    "\n",
    "The rendering will be in the form of a **jupyter notebook written like a report**: with a clearly announced plan, different sections and a conclusion.\n",
    "\n",
    "*A part of the grade will be given on the quality of the report (8 points), a part on the quality of the work done, and the respect of the methodology (6 points), a part on the quality of the prediction (6 points)*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "### Data Leakage (excerpts from [here](https://www.kaggle.com/alexisbcook/data-leakage))\n",
    "\n",
    "\"Data leakage (or leakage) happens when **your training data contains information about the target**, but similar data will not be available when the model is used for prediction. This leads to high performance on the training set (and possibly even the validation data), but the model will perform poorly in production.\n",
    "\n",
    "[...]\n",
    "\n",
    "**Target leakage** occurs when your predictors include data that will not be available at the time you make predictions. It is important to think about target leakage in terms of the timing or chronological order that data becomes available, not merely whether a feature helps make good predictions.\n",
    "\n",
    "[...] \n",
    "\n",
    "Validation is meant to be a measure of how the model does on data that it hasn't considered before. You can corrupt this process in subtle ways if the validation data affects the preprocessing behavior. This is sometimes called **train-test contamination**.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Table of Content\n",
    "\n",
    "1. **Introduction**\n",
    "\n",
    "    a. Overview of project steps\n",
    "    \n",
    "    b. Library imports and built functions\n",
    "\n",
    "\n",
    "2. **Data pre-processing**\n",
    "\n",
    "    a. Overview of used methods\n",
    "    \n",
    "    b. Pre-processing\n",
    "   \n",
    "   \n",
    "3. **Modeling**\n",
    "\n",
    "    a. Linear Regression\n",
    "    \n",
    "    b. KNN\n",
    "    \n",
    "    c. Naive Bayes\n",
    "    \n",
    "    d. Random Forest\n",
    " \n",
    " \n",
    "4. **Exploring hyperparameters of the best model**\n",
    "\n",
    "\n",
    "5. **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "### 1.1 Overview of project steps\n",
    "    \n",
    "The goal is the following:\n",
    "\n",
    "1. **Pre-process the dataset** into a ready-to-train-on array \n",
    "\n",
    "\n",
    "2. **Train and test our four selected model types**: Linear Regression, KNN, Naive Bayes, RandomForest\n",
    "\n",
    "\n",
    "3. **Select the most promising** of the four and **perform futher hyperparameter tuning** to increase the performance\n",
    "\n",
    "\n",
    "4. **Conclude** and propose further areas of explorations\n",
    "\n",
    "### 1.2 Library imports and built functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(tokenized_sentence):\n",
    "    \"\"\"\n",
    "    Removes the stop words from a tokenized sentence\n",
    "    \"\"\"\n",
    "    punctuation = [\".\", \",\", \"[\", \"]\", \"`\", \"(\", \")\", \"?\", \"'\", \"'s\", \":\", \"!\"]\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words += punctuation\n",
    "    return [w for w in tokenized_sentence if w not in stop_words]\n",
    "    \n",
    "def lemmatize(tokenized_sentence):\n",
    "    \"\"\"\n",
    "    Create a lemmatizer object and lematized tokenized items (e.g. sentences)\n",
    "    Might require running the following:\n",
    "        nltk.download('wordnet')\n",
    "    \"\"\"\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(w) for w in tokenized_sentence]\n",
    "\n",
    "sentence_processing = lambda sentence: \" \".join(\n",
    "    lemmatize(\n",
    "        remove_stop_words(\n",
    "            word_tokenize(str.lower(str(sentence)))\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data pre-processing\n",
    "\n",
    "### 2.1 Overview of used methods\n",
    "    \n",
    "<span style=\"color:red\">TBD</span>\n",
    "\n",
    "### 2.2 Pre-processing\n",
    "\n",
    "#### 1 - <u>Loading the *train* and *test* datasets:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_path = \"http://www.i3s.unice.fr/~riveill/dataset/MIMIC-III-readmission/\"\n",
    "train_set_path = online_path + \"train.csv.zip\"\n",
    "test_set_path = online_path + \"test.csv.zip\"\n",
    "\n",
    "local_train_set_path = \"./datasets/train.csv.zip\"\n",
    "local_test_set_path = \"./datasets/test.csv.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv(train_set_path)\n",
    "# df_train = pd.read_csv(test_set_path)\n",
    "\n",
    "df_train = pd.read_csv(local_train_set_path)\n",
    "df_test = pd.read_csv(local_test_set_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create two placeholder for the dataset so that we do not erase the original data/perform inplace modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = None\n",
    "X_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = None\n",
    "y_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - <u>Quick overview of the two sets:</u>\n",
    "\n",
    "- We find that the train dataset holds **2000** entries, while the test dataset holds **901** entries, i.e., a **69-31 train-test ratio**. *The size of the dataset is small, and a rule of thumb of at least a 80-20 train-test ratio is usually recommended. As such, we will keep the following sets as-is*.\n",
    "\n",
    "\n",
    "- There seems to be **several features with NaN values**, which will have to be dealt with.\n",
    "\n",
    "\n",
    "- The available features are of types **int64** or **Object**. We will have to transform those items accordingly\n",
    "\n",
    "\n",
    "- As seen in the [MIMIC-III Clinical Database Demo 1.4](https://physionet.org/content/mimiciii-demo/1.4/ADMISSIONS.csv), diagnosis starts as a string value containing a list of diagnosis separated by either '/', ';', ',' or '-' to say the least. Provided in the available dataset is a bag of word representation of that diagnosis column. Given that we see more than 0 or 1 values (i.e. true or false), it seems to indicate that **the Bag of Word approach may represent some kind of importance** (e.g. number of time the term appears). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>DAYS_NEXT_ADMIT</th>\n",
       "      <th>blood</th>\n",
       "      <th>circulatory</th>\n",
       "      <th>congenital</th>\n",
       "      <th>digestive</th>\n",
       "      <th>endocrine</th>\n",
       "      <th>genitourinary</th>\n",
       "      <th>infectious</th>\n",
       "      <th>...</th>\n",
       "      <th>mental</th>\n",
       "      <th>misc</th>\n",
       "      <th>muscular</th>\n",
       "      <th>neoplasms</th>\n",
       "      <th>nervous</th>\n",
       "      <th>pregnancy</th>\n",
       "      <th>prenatal</th>\n",
       "      <th>respiratory</th>\n",
       "      <th>skin</th>\n",
       "      <th>OUTPUT_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1210.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18155.690500</td>\n",
       "      <td>150103.483000</td>\n",
       "      <td>119.883433</td>\n",
       "      <td>0.482500</td>\n",
       "      <td>2.858000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.747500</td>\n",
       "      <td>1.389000</td>\n",
       "      <td>0.660500</td>\n",
       "      <td>0.438500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447500</td>\n",
       "      <td>0.430500</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.255500</td>\n",
       "      <td>0.421000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.972500</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.5050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>26240.378348</td>\n",
       "      <td>29205.036893</td>\n",
       "      <td>404.753993</td>\n",
       "      <td>0.735503</td>\n",
       "      <td>2.253969</td>\n",
       "      <td>0.196783</td>\n",
       "      <td>1.179593</td>\n",
       "      <td>1.329121</td>\n",
       "      <td>0.895902</td>\n",
       "      <td>0.809658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847114</td>\n",
       "      <td>0.739894</td>\n",
       "      <td>0.544511</td>\n",
       "      <td>0.704605</td>\n",
       "      <td>0.801299</td>\n",
       "      <td>0.151484</td>\n",
       "      <td>0.376709</td>\n",
       "      <td>1.199359</td>\n",
       "      <td>0.551753</td>\n",
       "      <td>0.5001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>100095.000000</td>\n",
       "      <td>-0.602083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1490.500000</td>\n",
       "      <td>124979.500000</td>\n",
       "      <td>5.383333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3103.500000</td>\n",
       "      <td>150743.500000</td>\n",
       "      <td>13.219792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25072.750000</td>\n",
       "      <td>174570.750000</td>\n",
       "      <td>25.327951</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99562.000000</td>\n",
       "      <td>199955.000000</td>\n",
       "      <td>3867.977778</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SUBJECT_ID        HADM_ID  DAYS_NEXT_ADMIT        blood  circulatory  \\\n",
       "count   2000.000000    2000.000000      1210.000000  2000.000000  2000.000000   \n",
       "mean   18155.690500  150103.483000       119.883433     0.482500     2.858000   \n",
       "std    26240.378348   29205.036893       404.753993     0.735503     2.253969   \n",
       "min       11.000000  100095.000000        -0.602083     0.000000     0.000000   \n",
       "25%     1490.500000  124979.500000         5.383333     0.000000     1.000000   \n",
       "50%     3103.500000  150743.500000        13.219792     0.000000     3.000000   \n",
       "75%    25072.750000  174570.750000        25.327951     1.000000     4.000000   \n",
       "max    99562.000000  199955.000000      3867.977778     5.000000    13.000000   \n",
       "\n",
       "        congenital    digestive    endocrine  genitourinary   infectious  ...  \\\n",
       "count  2000.000000  2000.000000  2000.000000    2000.000000  2000.000000  ...   \n",
       "mean      0.036000     0.747500     1.389000       0.660500     0.438500  ...   \n",
       "std       0.196783     1.179593     1.329121       0.895902     0.809658  ...   \n",
       "min       0.000000     0.000000     0.000000       0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000       0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     1.000000       0.000000     0.000000  ...   \n",
       "75%       0.000000     1.000000     2.000000       1.000000     1.000000  ...   \n",
       "max       2.000000     9.000000    10.000000       4.000000     7.000000  ...   \n",
       "\n",
       "            mental         misc     muscular    neoplasms      nervous  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean      0.447500     0.430500     0.216000     0.255500     0.421000   \n",
       "std       0.847114     0.739894     0.544511     0.704605     0.801299   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     1.000000     0.000000     0.000000     1.000000   \n",
       "max       9.000000     5.000000     5.000000     8.000000     7.000000   \n",
       "\n",
       "         pregnancy     prenatal  respiratory         skin  OUTPUT_LABEL  \n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000     2000.0000  \n",
       "mean      0.008000     0.119000     0.972500     0.189000        0.5050  \n",
       "std       0.151484     0.376709     1.199359     0.551753        0.5001  \n",
       "min       0.000000     0.000000     0.000000     0.000000        0.0000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000        0.0000  \n",
       "50%       0.000000     0.000000     1.000000     0.000000        1.0000  \n",
       "75%       0.000000     0.000000     2.000000     0.000000        1.0000  \n",
       "max       4.000000     5.000000     6.000000     6.000000        1.0000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>DAYS_NEXT_ADMIT</th>\n",
       "      <th>blood</th>\n",
       "      <th>circulatory</th>\n",
       "      <th>congenital</th>\n",
       "      <th>digestive</th>\n",
       "      <th>endocrine</th>\n",
       "      <th>genitourinary</th>\n",
       "      <th>infectious</th>\n",
       "      <th>...</th>\n",
       "      <th>mental</th>\n",
       "      <th>misc</th>\n",
       "      <th>muscular</th>\n",
       "      <th>neoplasms</th>\n",
       "      <th>nervous</th>\n",
       "      <th>pregnancy</th>\n",
       "      <th>prenatal</th>\n",
       "      <th>respiratory</th>\n",
       "      <th>skin</th>\n",
       "      <th>OUTPUT_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18306.197558</td>\n",
       "      <td>149172.830189</td>\n",
       "      <td>84.578517</td>\n",
       "      <td>0.466149</td>\n",
       "      <td>2.817980</td>\n",
       "      <td>0.044395</td>\n",
       "      <td>0.728080</td>\n",
       "      <td>1.372919</td>\n",
       "      <td>0.700333</td>\n",
       "      <td>0.468368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468368</td>\n",
       "      <td>0.436182</td>\n",
       "      <td>0.201998</td>\n",
       "      <td>0.243063</td>\n",
       "      <td>0.440622</td>\n",
       "      <td>0.015538</td>\n",
       "      <td>0.119867</td>\n",
       "      <td>0.931188</td>\n",
       "      <td>0.241953</td>\n",
       "      <td>0.503885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>26349.689656</td>\n",
       "      <td>29115.501914</td>\n",
       "      <td>304.437951</td>\n",
       "      <td>0.691390</td>\n",
       "      <td>2.256878</td>\n",
       "      <td>0.231479</td>\n",
       "      <td>1.165418</td>\n",
       "      <td>1.406611</td>\n",
       "      <td>0.944628</td>\n",
       "      <td>0.804397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919147</td>\n",
       "      <td>0.752463</td>\n",
       "      <td>0.538760</td>\n",
       "      <td>0.682942</td>\n",
       "      <td>0.784625</td>\n",
       "      <td>0.253383</td>\n",
       "      <td>0.354423</td>\n",
       "      <td>1.184030</td>\n",
       "      <td>0.624726</td>\n",
       "      <td>0.500263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>100039.000000</td>\n",
       "      <td>-0.454167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1521.000000</td>\n",
       "      <td>123423.000000</td>\n",
       "      <td>5.100868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3176.000000</td>\n",
       "      <td>147718.000000</td>\n",
       "      <td>11.302431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25256.000000</td>\n",
       "      <td>174749.000000</td>\n",
       "      <td>22.211632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99982.000000</td>\n",
       "      <td>199807.000000</td>\n",
       "      <td>3543.101389</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SUBJECT_ID        HADM_ID  DAYS_NEXT_ADMIT       blood  circulatory  \\\n",
       "count    901.000000     901.000000       526.000000  901.000000   901.000000   \n",
       "mean   18306.197558  149172.830189        84.578517    0.466149     2.817980   \n",
       "std    26349.689656   29115.501914       304.437951    0.691390     2.256878   \n",
       "min        6.000000  100039.000000        -0.454167    0.000000     0.000000   \n",
       "25%     1521.000000  123423.000000         5.100868    0.000000     1.000000   \n",
       "50%     3176.000000  147718.000000        11.302431    0.000000     2.000000   \n",
       "75%    25256.000000  174749.000000        22.211632    1.000000     4.000000   \n",
       "max    99982.000000  199807.000000      3543.101389    4.000000    12.000000   \n",
       "\n",
       "       congenital   digestive   endocrine  genitourinary  infectious  ...  \\\n",
       "count  901.000000  901.000000  901.000000     901.000000  901.000000  ...   \n",
       "mean     0.044395    0.728080    1.372919       0.700333    0.468368  ...   \n",
       "std      0.231479    1.165418    1.406611       0.944628    0.804397  ...   \n",
       "min      0.000000    0.000000    0.000000       0.000000    0.000000  ...   \n",
       "25%      0.000000    0.000000    0.000000       0.000000    0.000000  ...   \n",
       "50%      0.000000    0.000000    1.000000       0.000000    0.000000  ...   \n",
       "75%      0.000000    1.000000    2.000000       1.000000    1.000000  ...   \n",
       "max      2.000000    7.000000    7.000000       5.000000    7.000000  ...   \n",
       "\n",
       "           mental        misc    muscular   neoplasms     nervous   pregnancy  \\\n",
       "count  901.000000  901.000000  901.000000  901.000000  901.000000  901.000000   \n",
       "mean     0.468368    0.436182    0.201998    0.243063    0.440622    0.015538   \n",
       "std      0.919147    0.752463    0.538760    0.682942    0.784625    0.253383   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      1.000000    1.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "max      6.000000    5.000000    5.000000    5.000000    4.000000    5.000000   \n",
       "\n",
       "         prenatal  respiratory        skin  OUTPUT_LABEL  \n",
       "count  901.000000   901.000000  901.000000    901.000000  \n",
       "mean     0.119867     0.931188    0.241953      0.503885  \n",
       "std      0.354423     1.184030    0.624726      0.500263  \n",
       "min      0.000000     0.000000    0.000000      0.000000  \n",
       "25%      0.000000     0.000000    0.000000      0.000000  \n",
       "50%      0.000000     1.000000    0.000000      1.000000  \n",
       "75%      0.000000     2.000000    0.000000      1.000000  \n",
       "max      3.000000     7.000000    6.000000      1.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 34 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   SUBJECT_ID          2000 non-null   int64  \n",
      " 1   HADM_ID             2000 non-null   int64  \n",
      " 2   ADMITTIME           2000 non-null   object \n",
      " 3   DISCHTIME           2000 non-null   object \n",
      " 4   DAYS_NEXT_ADMIT     1210 non-null   float64\n",
      " 5   NEXT_ADMITTIME      1210 non-null   object \n",
      " 6   ADMISSION_TYPE      2000 non-null   object \n",
      " 7   DEATHTIME           158 non-null    object \n",
      " 8   DISCHARGE_LOCATION  2000 non-null   object \n",
      " 9   INSURANCE           2000 non-null   object \n",
      " 10  MARITAL_STATUS      1924 non-null   object \n",
      " 11  ETHNICITY           2000 non-null   object \n",
      " 12  DIAGNOSIS           1998 non-null   object \n",
      " 13  TEXT                1925 non-null   object \n",
      " 14  GENDER              2000 non-null   object \n",
      " 15  DOB                 2000 non-null   object \n",
      " 16  blood               2000 non-null   int64  \n",
      " 17  circulatory         2000 non-null   int64  \n",
      " 18  congenital          2000 non-null   int64  \n",
      " 19  digestive           2000 non-null   int64  \n",
      " 20  endocrine           2000 non-null   int64  \n",
      " 21  genitourinary       2000 non-null   int64  \n",
      " 22  infectious          2000 non-null   int64  \n",
      " 23  injury              2000 non-null   int64  \n",
      " 24  mental              2000 non-null   int64  \n",
      " 25  misc                2000 non-null   int64  \n",
      " 26  muscular            2000 non-null   int64  \n",
      " 27  neoplasms           2000 non-null   int64  \n",
      " 28  nervous             2000 non-null   int64  \n",
      " 29  pregnancy           2000 non-null   int64  \n",
      " 30  prenatal            2000 non-null   int64  \n",
      " 31  respiratory         2000 non-null   int64  \n",
      " 32  skin                2000 non-null   int64  \n",
      " 33  OUTPUT_LABEL        2000 non-null   int64  \n",
      "dtypes: float64(1), int64(20), object(13)\n",
      "memory usage: 531.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 901 entries, 0 to 900\n",
      "Data columns (total 34 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   SUBJECT_ID          901 non-null    int64  \n",
      " 1   HADM_ID             901 non-null    int64  \n",
      " 2   ADMITTIME           901 non-null    object \n",
      " 3   DISCHTIME           901 non-null    object \n",
      " 4   DAYS_NEXT_ADMIT     526 non-null    float64\n",
      " 5   NEXT_ADMITTIME      526 non-null    object \n",
      " 6   ADMISSION_TYPE      901 non-null    object \n",
      " 7   DEATHTIME           58 non-null     object \n",
      " 8   DISCHARGE_LOCATION  901 non-null    object \n",
      " 9   INSURANCE           901 non-null    object \n",
      " 10  MARITAL_STATUS      861 non-null    object \n",
      " 11  ETHNICITY           901 non-null    object \n",
      " 12  DIAGNOSIS           901 non-null    object \n",
      " 13  TEXT                871 non-null    object \n",
      " 14  GENDER              901 non-null    object \n",
      " 15  DOB                 901 non-null    object \n",
      " 16  blood               901 non-null    int64  \n",
      " 17  circulatory         901 non-null    int64  \n",
      " 18  congenital          901 non-null    int64  \n",
      " 19  digestive           901 non-null    int64  \n",
      " 20  endocrine           901 non-null    int64  \n",
      " 21  genitourinary       901 non-null    int64  \n",
      " 22  infectious          901 non-null    int64  \n",
      " 23  injury              901 non-null    int64  \n",
      " 24  mental              901 non-null    int64  \n",
      " 25  misc                901 non-null    int64  \n",
      " 26  muscular            901 non-null    int64  \n",
      " 27  neoplasms           901 non-null    int64  \n",
      " 28  nervous             901 non-null    int64  \n",
      " 29  pregnancy           901 non-null    int64  \n",
      " 30  prenatal            901 non-null    int64  \n",
      " 31  respiratory         901 non-null    int64  \n",
      " 32  skin                901 non-null    int64  \n",
      " 33  OUTPUT_LABEL        901 non-null    int64  \n",
      "dtypes: float64(1), int64(20), object(13)\n",
      "memory usage: 239.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - <u>Understanding data leakage:</u>\n",
    "\n",
    "It appears that **a single person**, represented by a single subject ID, **can have several entries in the dataset** (Based on the [MIMIC-III information](https://mimic.physionet.org/mimictables/admissions/), **HADM_ID** represents a single patient’s admission to the hospital and **SUBJECT_ID** indicates that a single patient who can have multiple admissions to the hospital). <span style=\"color:red\">To avoid data leakage, we must **identify features which we will need to exclude** due to leakage</span>.\n",
    "\n",
    "Our goal is also **individualizing each row** so that we reduce the dependencies between each rows. This is key in order to avoid data leakage.\n",
    "\n",
    "**Example with subject_id 17**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2, 15,  3,  5,  4,  6,  8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we look for the number of times a single patient has been admitted to a hospital. \n",
    "# We find that a single patient may have been admitted up to 15 times in the training set\n",
    "\n",
    "df_train.pivot_table(index = ['SUBJECT_ID'], aggfunc ='size').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SUBJECT_ID\n",
       "11       1\n",
       "17       2\n",
       "19       1\n",
       "21       1\n",
       "22       1\n",
       "        ..\n",
       "99312    1\n",
       "99384    1\n",
       "99464    1\n",
       "99538    1\n",
       "99562    1\n",
       "Length: 1758, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We identify that subject 17 has been admitted twice\n",
    "\n",
    "df_train.pivot_table(index = ['SUBJECT_ID'], aggfunc ='size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DISCHTIME</th>\n",
       "      <th>DAYS_NEXT_ADMIT</th>\n",
       "      <th>NEXT_ADMITTIME</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>DEATHTIME</th>\n",
       "      <th>DISCHARGE_LOCATION</th>\n",
       "      <th>INSURANCE</th>\n",
       "      <th>...</th>\n",
       "      <th>mental</th>\n",
       "      <th>misc</th>\n",
       "      <th>muscular</th>\n",
       "      <th>neoplasms</th>\n",
       "      <th>nervous</th>\n",
       "      <th>pregnancy</th>\n",
       "      <th>prenatal</th>\n",
       "      <th>respiratory</th>\n",
       "      <th>skin</th>\n",
       "      <th>OUTPUT_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>17</td>\n",
       "      <td>161087</td>\n",
       "      <td>2135-05-09 14:11:00</td>\n",
       "      <td>2135-05-13 14:40:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Private</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>17</td>\n",
       "      <td>194023</td>\n",
       "      <td>2134-12-27 07:15:00</td>\n",
       "      <td>2134-12-31 16:05:00</td>\n",
       "      <td>128.920833</td>\n",
       "      <td>2135-05-09 14:11:00</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Private</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SUBJECT_ID  HADM_ID            ADMITTIME            DISCHTIME  \\\n",
       "1182          17   161087  2135-05-09 14:11:00  2135-05-13 14:40:00   \n",
       "1710          17   194023  2134-12-27 07:15:00  2134-12-31 16:05:00   \n",
       "\n",
       "      DAYS_NEXT_ADMIT       NEXT_ADMITTIME ADMISSION_TYPE DEATHTIME  \\\n",
       "1182              NaN                  NaN      EMERGENCY       NaN   \n",
       "1710       128.920833  2135-05-09 14:11:00       ELECTIVE       NaN   \n",
       "\n",
       "     DISCHARGE_LOCATION INSURANCE  ... mental misc muscular neoplasms nervous  \\\n",
       "1182   HOME HEALTH CARE   Private  ...      1    1        2         0       0   \n",
       "1710   HOME HEALTH CARE   Private  ...      0    0        0         0       0   \n",
       "\n",
       "     pregnancy  prenatal  respiratory  skin  OUTPUT_LABEL  \n",
       "1182         0         0            1     0             0  \n",
       "1710         0         0            0     0             0  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train[\"SUBJECT_ID\"]==17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to identify whether people who have been readmitted always have a single row per admission. Based on simple data wrangling, it appears that **some patients have a readmission time but do not have multiple lines associated to their case**.\n",
    "\n",
    "**Example with subject_id 937**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DISCHTIME</th>\n",
       "      <th>DAYS_NEXT_ADMIT</th>\n",
       "      <th>NEXT_ADMITTIME</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>DEATHTIME</th>\n",
       "      <th>DISCHARGE_LOCATION</th>\n",
       "      <th>INSURANCE</th>\n",
       "      <th>...</th>\n",
       "      <th>mental</th>\n",
       "      <th>misc</th>\n",
       "      <th>muscular</th>\n",
       "      <th>neoplasms</th>\n",
       "      <th>nervous</th>\n",
       "      <th>pregnancy</th>\n",
       "      <th>prenatal</th>\n",
       "      <th>respiratory</th>\n",
       "      <th>skin</th>\n",
       "      <th>OUTPUT_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>937</td>\n",
       "      <td>148592</td>\n",
       "      <td>2163-01-20 18:39:00</td>\n",
       "      <td>2163-01-24 08:00:00</td>\n",
       "      <td>0.061806</td>\n",
       "      <td>2163-01-24 09:29:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>2163-01-26 08:00:00</td>\n",
       "      <td>DEAD/EXPIRED</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID  HADM_ID            ADMITTIME            DISCHTIME  \\\n",
       "0         937   148592  2163-01-20 18:39:00  2163-01-24 08:00:00   \n",
       "\n",
       "   DAYS_NEXT_ADMIT       NEXT_ADMITTIME ADMISSION_TYPE            DEATHTIME  \\\n",
       "0         0.061806  2163-01-24 09:29:00      EMERGENCY  2163-01-26 08:00:00   \n",
       "\n",
       "  DISCHARGE_LOCATION INSURANCE  ... mental misc muscular neoplasms nervous  \\\n",
       "0       DEAD/EXPIRED  Medicare  ...      0    0        0         0       1   \n",
       "\n",
       "  pregnancy  prenatal  respiratory  skin  OUTPUT_LABEL  \n",
       "0         0         0            0     0             1  \n",
       "\n",
       "[1 rows x 34 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We find that subject_id 937 has been admitted twice but has only one single record\n",
    "# in the training dataset\n",
    "\n",
    "df_train[df_train[\"SUBJECT_ID\"]==937]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also find that some subject have **missing admissions along with mismatching dates**. <span style=\"color:red\">This implies that there is no time series available to us</span>. Each admission time can be construed as *somewhat* independent from the other if we trim elements that could link them to each other. \n",
    "\n",
    "**Example with subject_id 808**:\n",
    "\n",
    "*The admit times are mismatched, and that there are 3 admissions with each showing a next admission time, implying at least one admission is missing from the dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DISCHTIME</th>\n",
       "      <th>DAYS_NEXT_ADMIT</th>\n",
       "      <th>NEXT_ADMITTIME</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>DEATHTIME</th>\n",
       "      <th>DISCHARGE_LOCATION</th>\n",
       "      <th>INSURANCE</th>\n",
       "      <th>...</th>\n",
       "      <th>mental</th>\n",
       "      <th>misc</th>\n",
       "      <th>muscular</th>\n",
       "      <th>neoplasms</th>\n",
       "      <th>nervous</th>\n",
       "      <th>pregnancy</th>\n",
       "      <th>prenatal</th>\n",
       "      <th>respiratory</th>\n",
       "      <th>skin</th>\n",
       "      <th>OUTPUT_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>808</td>\n",
       "      <td>197130</td>\n",
       "      <td>2181-11-16 08:18:00</td>\n",
       "      <td>2181-11-23 09:04:00</td>\n",
       "      <td>8.701389</td>\n",
       "      <td>2181-12-02 01:54:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Private</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>808</td>\n",
       "      <td>100677</td>\n",
       "      <td>2181-07-12 20:11:00</td>\n",
       "      <td>2181-07-17 13:14:00</td>\n",
       "      <td>13.395833</td>\n",
       "      <td>2181-07-30 22:44:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Private</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>808</td>\n",
       "      <td>139077</td>\n",
       "      <td>2181-05-11 16:57:00</td>\n",
       "      <td>2181-05-16 11:58:00</td>\n",
       "      <td>13.701389</td>\n",
       "      <td>2181-05-30 04:48:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Private</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SUBJECT_ID  HADM_ID            ADMITTIME            DISCHTIME  \\\n",
       "553          808   197130  2181-11-16 08:18:00  2181-11-23 09:04:00   \n",
       "1189         808   100677  2181-07-12 20:11:00  2181-07-17 13:14:00   \n",
       "1995         808   139077  2181-05-11 16:57:00  2181-05-16 11:58:00   \n",
       "\n",
       "      DAYS_NEXT_ADMIT       NEXT_ADMITTIME ADMISSION_TYPE DEATHTIME  \\\n",
       "553          8.701389  2181-12-02 01:54:00      EMERGENCY       NaN   \n",
       "1189        13.395833  2181-07-30 22:44:00      EMERGENCY       NaN   \n",
       "1995        13.701389  2181-05-30 04:48:00      EMERGENCY       NaN   \n",
       "\n",
       "     DISCHARGE_LOCATION INSURANCE  ... mental misc muscular neoplasms nervous  \\\n",
       "553    HOME HEALTH CARE   Private  ...      0    0        0         2       0   \n",
       "1189   HOME HEALTH CARE   Private  ...      0    1        0         3       0   \n",
       "1995               HOME   Private  ...      0    0        0         0       0   \n",
       "\n",
       "     pregnancy  prenatal  respiratory  skin  OUTPUT_LABEL  \n",
       "553          0         0            3     0             1  \n",
       "1189         0         0            0     0             1  \n",
       "1995         0         0            2     0             1  \n",
       "\n",
       "[3 rows x 34 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we see that subject_id 808 has three referenced admissions but the last one mentions \n",
    "# a next admission that is not referenced\n",
    "\n",
    "df_train[df_train[\"SUBJECT_ID\"]==808]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also find features which will leak information about our target variable. To prove this, we go back to our subject_id 937.\n",
    "\n",
    "**Example with subject_id 937**:\n",
    "\n",
    "We see that DISCHARGE_LOCATION and TEXT hold important data with regards to the outcome of the patient's stay. In the case of subject_id 937 (75 year old man with a history of hypertension), we see that the person died during their care at the hospital and that mention of their death (term used: expired) is referenced in both cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    DEAD/EXPIRED\n",
       "Name: DISCHARGE_LOCATION, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We find that the cell DISCHARGE_LOCATION holds important data on the fate of the\n",
    "# patient\n",
    "\n",
    "df_train[df_train[\"SUBJECT_ID\"]==937][\"DISCHARGE_LOCATION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Admission Date:  [**2163-1-20**]              Discharge Date:   [**2163-1-24**]\\n\\nDate of Birth:  [**2087-9-24**]             Sex:   M\\n\\nService: NEUROLOGY\\n\\nAllergies:\\nPatient recorded as having No Known Allergies to Drugs\\n\\nAttending:[**First Name3 (LF) 5868**]\\nChief Complaint:\\ntransfer from ICH with intra-parenchymal bleed\\n\\nMajor Surgical or Invasive Procedure:\\nnone\\n\\nHistory of Present Illness:\\nThe patient is a 75 year old man with a history of hypertension\\nand high cholesterol, now presenting on transfer from an OSH\\nwith\\na large right intraparenchymal cerebral bleed.  As per his\\nchart, he originally presented to the OSH with the complaint of\\ninability to feel his right leg.  An angiogram of the leg\\nuncovered a right femoral artery occlusion and he was given t-\\nPA (iv).  The next morning, the patient developed a left\\nhemiparesis with left facial droop and a right gaze preference.\\nAn emergent CT scan of his brain showed multiple hemorrhages\\nprimarily in the right frontal lobe, but also including the left\\nparietal lobe and right cerebellum.\\n\\nReview of Systems:\\n-not obtainable\\n\\n\\nPast Medical History:\\n-umbilical hernia repair\\n-gall bladder removal in [**2160**]\\n-hypertension\\n-high cholesterol\\n-aortofemoral + fem-[**Doctor Last Name **] bypass [**2156**]\\n-TURP in [**2152**]\\n\\n\\nSocial History:\\n-no known history of tobacco or alcohol\\n\\n\\nFamily History:\\n-father died at age [**Age over 90 **]\\n-mother died of heart attack\\n\\n\\nPhysical Exam:\\nVitals:  98.6  140/70  54  18  100% intubated\\nGeneral:  elderly man, moving right arm in bed, some distress\\nNeck: supple\\nLungs:  coarse breath sounds\\nCV: regular rate and rhythm, bradycardic\\nAbdomen:  non-tender, non-distended, bowel sounds present\\nExt: warm, no edema\\n\\nNeurologic Examination:\\nNo eye opening to loud voice or sternal rub; not following\\nsimple\\ncommands to squeeze hands or open eyes; pupils minimally\\nreactive\\nto light but equal; no dolls eye movements; left facial droop;\\nspontaneous movement of RUE, RLL, and LLL, no movement of LUE;\\nwithdraws to pain on all extremities except left arm-here he\\nextensor postures; reflexes brisk throughout with no large\\nasymmetries; toe upgoing on left, down on right\\n\\n\\nPertinent Results:\\ncbc:  13.6/20.0/182\\nchem:  135/4.1  102/24  17/0.7  122\\nc/m/p:  8.7/2.2/2.2\\ncoags:  14.7/26.9/1.4\\n\\nHead CT:  multiple discreet areas of hemorrhage, prominent in\\nthe\\nright frontal lobe; intraventricular extension; some edema with\\nmass effect\\n\\n\\nBrief Hospital Course:\\nThe patient was admitted from an OSH for management of a large\\nintra-parenchymal hemmorrhage.  Patient patient had a poor\\nneurologic examination on admission.  The patient continued to\\ndeteriorate and on hospital day #5 was pronounced brain dead.\\nAs per the families wishes, he became an organ donor.\\n\\nMedications on Admission:\\n-nadolol\\n-hctz\\n-lisinopril\\n-zocor\\n-baby asa\\n-mvi\\n-trental\\n\\n\\nDischarge Medications:\\nn/a\\n\\nDischarge Disposition:\\nExpired\\n\\nDischarge Diagnosis:\\n1.  intraparenchymal hemmorrhage\\n\\nDischarge Condition:\\nexpired\\n\\nDischarge Instructions:\\nn/a\\n\\nFollowup Instructions:\\nn/a\\n\\n\\nCompleted by:[**2163-3-14**]']\n"
     ]
    }
   ],
   "source": [
    "# We find that the cell TEXT holds important data on the fate of the patient:\n",
    "#     Discharge Disposition:\\nExpired\\n\\nDischarge Diagnosis:\\n1.  \n",
    "#     intraparenchymal hemmorrhage\\n\\nDischarge Condition:\\nexpired\n",
    "\n",
    "print(df_train[df_train[\"SUBJECT_ID\"]==937][\"TEXT\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - <u>Selecting our feature variables:</u>\n",
    "\n",
    "As such, we decide to focus on the following features:\n",
    "\n",
    "- Age (which we will have to construct out of DOB and ADMITTIME)\n",
    "- Gender\n",
    "- Marital Status\n",
    "- Ethnicity\n",
    "- Insurance\n",
    "- Admission Type\n",
    "- Length of stay (which we will have to construct out of DISCTIME and ADMITTIME)\n",
    "- diagnosis\n",
    "\n",
    "<u><span style=\"color:red\">Note on **ETHNICITY**</span>:</u>\n",
    "\n",
    "> It is important to note that **ethnic/racial data is a controversial topic in AI**. The goal is to **avoid racial profiling as well as racial discrimination** -- especially in health. \n",
    ">\n",
    "> It happens that **systemic racism and poverty affecting minorities in the United States**. We recall that the [MIMIC dataset is a relational database containing tables of data relating to patient who stayed within the intensive care units](https://mimic.physionet.org/gettingstarted/overview/) at [Beth Israel Deaconess Medical Center in Boston, MA, USA](https://en.wikipedia.org/wiki/Beth_Israel_Deaconess_Medical_Center). The hospital is a *private* teaching center attached to the Harvard Medical School. \n",
    ">\n",
    "> Ethnicity will likely have a **strong impact on both the quality of their care, their access to insurance, and in the end their potential rate of readmission, etc**.\n",
    ">\n",
    "> As such, <span style=\"color:red\">we will need to see if ethnicity has a strong effect on our end result, and if possible, we can do without it</span>.\n",
    "\n",
    "<u>Note on **TEXT** and **DISCHARGE_LOCATION**:</u>\n",
    "\n",
    "> As we saw above, TEXT and DISCHARGE_LOCATION may hold important information on the end fate of the patient, meaning we cannot include those features as **it would leak information with regards to the outcome we want to predict**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_columns = [\"DOB\", \"GENDER\", \"MARITAL_STATUS\", \"ETHNICITY\", \"INSURANCE\", \n",
    "                \"ADMISSION_TYPE\", \"DIAGNOSIS\", \"ADMITTIME\", \"DISCHTIME\"]\n",
    "\n",
    "X_train = df_train[kept_columns]\n",
    "X_test = df_test[kept_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOB</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>MARITAL_STATUS</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>INSURANCE</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DISCHTIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2087-09-24 00:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OTHER/UNKNOWN</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>INTRACRANIAL HEMORRHAGE</td>\n",
       "      <td>2163-01-20 18:39:00</td>\n",
       "      <td>2163-01-24 08:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   DOB GENDER MARITAL_STATUS      ETHNICITY INSURANCE  \\\n",
       "0  2087-09-24 00:00:00      M            NaN  OTHER/UNKNOWN  Medicare   \n",
       "\n",
       "  ADMISSION_TYPE                DIAGNOSIS            ADMITTIME  \\\n",
       "0      EMERGENCY  INTRACRANIAL HEMORRHAGE  2163-01-20 18:39:00   \n",
       "\n",
       "             DISCHTIME  \n",
       "0  2163-01-24 08:00:00  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 - <u>Building our end feature variables:</u>\n",
    "\n",
    "1. **LENGTH_OF_STAY** (in days)\n",
    "\n",
    "> We build our length of stay variable by taking the difference between ADMITTIME and DISCTIME in days\n",
    "\n",
    "2. **AGE** (in year)\n",
    "\n",
    "> We build our age variable by taking the difference between ADMITTIME and DOB in year\n",
    ">\n",
    "> Some ages are impossible, leading to think that some values were misrecorded. We replace those with the average age of the Train dataset (excluding those misrecorded ages).\n",
    "\n",
    "3. **GENDER, MARITAL_STATUS, ETHNICITY, INSURANCE, ADMISSION_TYPE**\n",
    "\n",
    "> We build one-hot encoding for those variables\n",
    "\n",
    "4. **DIAGNOSIS**\n",
    "\n",
    "> We want to build our own Bag of Word representation using the sklearn CountVectorizer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LENGTH_OF_STAY\n",
    "\n",
    "# 1. convert dates to datetime\n",
    "# 2. calculate the timedelta\n",
    "# 3. convert to float value (in days)\n",
    "X_train[\"ADMITTIME\"] = pd.to_datetime(X_train[\"ADMITTIME\"])\n",
    "X_train[\"DISCHTIME\"] = pd.to_datetime(X_train[\"DISCHTIME\"])\n",
    "X_train[\"LENGTH_OF_STAY\"] = X_train[\"DISCHTIME\"] - X_train[\"ADMITTIME\"]\n",
    "X_train[\"LENGTH_OF_STAY\"] = X_train[\"LENGTH_OF_STAY\"].dt.total_seconds() / (24 * 60 * 60)\n",
    "\n",
    "X_test[\"ADMITTIME\"] = pd.to_datetime(X_test[\"ADMITTIME\"])\n",
    "X_test[\"DISCHTIME\"] = pd.to_datetime(X_test[\"DISCHTIME\"])\n",
    "X_test[\"LENGTH_OF_STAY\"] = X_test[\"DISCHTIME\"] - X_test[\"ADMITTIME\"]\n",
    "X_test[\"LENGTH_OF_STAY\"] = X_test[\"LENGTH_OF_STAY\"].dt.total_seconds() / (24 * 60 * 60)\n",
    "\n",
    " # we drop columns as they are not useful anymore\n",
    "X_train.drop([\"DISCHTIME\"], axis = 1, inplace = True)\n",
    "X_test.drop([\"DISCHTIME\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGE\n",
    "\n",
    "# 1. convert dates to year\n",
    "# 2. calculate the float value difference\n",
    "X_train[\"DOB\"] = pd.to_datetime(X_train[\"DOB\"]).dt.year\n",
    "X_train[\"ADMITTIME\"] = X_train[\"ADMITTIME\"].dt.year\n",
    "X_train[\"AGE\"] = X_train[\"ADMITTIME\"] - X_train[\"DOB\"]\n",
    "\n",
    "X_test[\"DOB\"] = pd.to_datetime(X_test[\"DOB\"]).dt.year\n",
    "X_test[\"ADMITTIME\"] = X_test[\"ADMITTIME\"].dt.year\n",
    "X_test[\"AGE\"] = X_test[\"ADMITTIME\"] - X_test[\"DOB\"]\n",
    "\n",
    " # we drop columns as they are not useful anymore\n",
    "X_train.drop([\"ADMITTIME\", \"DOB\"], axis = 1, inplace = True)\n",
    "X_test.drop([\"ADMITTIME\", \"DOB\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that some ages are impossible, leading to think that we have misrecorded values. **All in all 119 rows are impacted**. This is an issue we need to remedy as we can't throw away 5%+ of our dataset.\n",
    "\n",
    "The way to deal with those is to replace the value with the average age of the rest of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 300, 301, 302, 303, 305, 306, 307, 308, 310]\n",
      "\n",
      "[0, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 300, 301, 302, 303, 305, 308]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(X_train[\"AGE\"].unique()),\n",
    "      sorted(X_test[\"AGE\"].unique()),\n",
    "      sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[X_train[\"AGE\"]>89])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.22328548644338\n"
     ]
    }
   ],
   "source": [
    "average_age = X_train[X_train[\"AGE\"]<=89][\"AGE\"].mean()\n",
    "print(average_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[(X_train.AGE > 89), 'AGE'] = average_age\n",
    "X_test.loc[(X_test.AGE > 89), 'AGE'] = average_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENDER, MARITAL_STATUS, ETHNICITY, INSURANCE, ADMISSION_TYPE\n",
    "\n",
    "dummy_list = [\"GENDER\", \"MARITAL_STATUS\", \"ETHNICITY\", \"INSURANCE\", \"ADMISSION_TYPE\"]\n",
    "\n",
    "X_train = pd.get_dummies(X_train, columns = dummy_list)\n",
    "X_test = pd.get_dummies(X_test, columns = dummy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNOSIS\n",
    "\n",
    "# Pre-processing the content of the DIAGNOSIS column\n",
    "X_train[\"DIAGNOSIS\"] = X_train[\"DIAGNOSIS\"].apply(sentence_processing)\n",
    "X_test[\"DIAGNOSIS\"] = X_test[\"DIAGNOSIS\"].apply(sentence_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying CountVectorizer to the pre-processed DIAGNOSIS column\n",
    "\n",
    "# We declare and fit the CountVectorizer object\n",
    "cv = CountVectorizer(analyzer=\"word\", ngram_range=(1,1), stop_words=\"english\")\n",
    "cv.fit(X_train[\"DIAGNOSIS\"].tolist())\n",
    "\n",
    "# We transform the diagnosis column using the count vectorizer\n",
    "tf = lambda s: cv.transform([s]).todense().tolist()[0]\n",
    "X_train[\"DIAGNOSIS\"] = X_train[\"DIAGNOSIS\"].apply(tf)\n",
    "X_test[\"DIAGNOSIS\"] = X_test[\"DIAGNOSIS\"].apply(tf)\n",
    "\n",
    "# We expand the resulting feature matrix into individual columns\n",
    "X_train[cv.get_feature_names()] = pd.DataFrame(X_train[\"DIAGNOSIS\"].tolist(), \n",
    "                                               index= X_train.index)\n",
    "X_test[cv.get_feature_names()] = pd.DataFrame(X_test[\"DIAGNOSIS\"].tolist(), \n",
    "                                               index= X_test.index)\n",
    "\n",
    "# We drop the DIAGNOSIS column\n",
    "X_train.drop([\"DIAGNOSIS\"], axis=1, inplace=True)\n",
    "X_test.drop([\"DIAGNOSIS\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of diagnosis features: 819.\n",
      "\n",
      "['1st', '21', '22', 'abcess', 'abd', 'abdcess', 'abdomal', 'abdomen', 'abdominal', 'ablation', 'abscess', 'abuse', 'accending', 'access', 'accident', 'account', 'achalasia', 'acidosis', 'acitic', 'acsites', 'acute', 'advancement', 'afib', 'aicd', 'air', 'airway', 'alcohol', 'als', 'altered', 'aml', 'anasarca', 'anemia', 'aneursym', 'aneurysm', 'angina', 'angio', 'angiogram', 'angioplasty', 'ankle', 'anomaly', 'anterior', 'antibiotic', 'anticholinergic', 'aorta', 'aortic', 'appendicitis', 'approach', 'ar', 'arachnoid', 'arch', 'arf', 'arrest', 'arterial', 'artery', 'ascending', 'ascites', 'aspiration', 'assault', 'asthma', 'asthmaticus', 'ataxia', 'atriacure', 'atrial', 'atrioventricular', 'attach', 'attack', 'aureus', 'av', 'avascular', 'avr', 'axillo', 'bacteremia', 'bacterial', 'benign', 'bental', 'bentall', 'benzodiazepine', 'bi', 'bifemoral', 'bilateral', 'bile', 'bili', 'biliary', 'biventricular', 'bladder', 'bled', 'bleed', 'bleeding', 'block', 'blomyscin', 'blood', 'blunt', 'bone', 'bowel', 'bowl', 'bradycardia', 'brain', 'breast', 'breath', 'bright']\n"
     ]
    }
   ],
   "source": [
    "# first 100 elements of the feature_names of the Count Vectorizer\n",
    "print(f\"Number of diagnosis features: {len(cv.get_feature_names())}.\",\n",
    "      cv.get_feature_names()[:100],\n",
    "      sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train.head(1), X_test.head(1), X_train.dtypes, X_test.dtypes, sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6 - <u>Building our target variable:</u>\n",
    "    \n",
    "We want to estimate the re-hospitalization rate of a patient. The question is then **how to represent re-hospitalization**?\n",
    "\n",
    "Two approaches are possible:\n",
    "\n",
    "- **regression**: Predicting the number of days between discharge and readmission for a patient\n",
    "    - We can predict the number of days between discharge and readmission using the DAYS_NEXT_ADMIT feature that is available to us\n",
    "    - The main issue of DAYS_NEXT_ADMIT is how to represent the absence of readmission (NaN in the dataset)\n",
    "\n",
    "- **classification**: Predicting if a patient will **i)** be readmitted at some point, **ii)** die, **iii)** being discharged without readmission\n",
    "    - We can assign a tag to each of the scenarios above which will be used to perform classification\n",
    "    \n",
    "With regards to constructing our y values, <span style=\"color:red\">we find that some elements are problematic</span>. For instance, the subject_id 937 indicates both a next admission time and a death time in the same row. Via a quick check, we see that there are several cases like this, but each subject_ID is only mentioned once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DISCHTIME</th>\n",
       "      <th>DAYS_NEXT_ADMIT</th>\n",
       "      <th>NEXT_ADMITTIME</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>DEATHTIME</th>\n",
       "      <th>DISCHARGE_LOCATION</th>\n",
       "      <th>INSURANCE</th>\n",
       "      <th>...</th>\n",
       "      <th>mental</th>\n",
       "      <th>misc</th>\n",
       "      <th>muscular</th>\n",
       "      <th>neoplasms</th>\n",
       "      <th>nervous</th>\n",
       "      <th>pregnancy</th>\n",
       "      <th>prenatal</th>\n",
       "      <th>respiratory</th>\n",
       "      <th>skin</th>\n",
       "      <th>OUTPUT_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>937</td>\n",
       "      <td>148592</td>\n",
       "      <td>2163-01-20 18:39:00</td>\n",
       "      <td>2163-01-24 08:00:00</td>\n",
       "      <td>0.061806</td>\n",
       "      <td>2163-01-24 09:29:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>2163-01-26 08:00:00</td>\n",
       "      <td>DEAD/EXPIRED</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID  HADM_ID            ADMITTIME            DISCHTIME  \\\n",
       "0         937   148592  2163-01-20 18:39:00  2163-01-24 08:00:00   \n",
       "\n",
       "   DAYS_NEXT_ADMIT       NEXT_ADMITTIME ADMISSION_TYPE            DEATHTIME  \\\n",
       "0         0.061806  2163-01-24 09:29:00      EMERGENCY  2163-01-26 08:00:00   \n",
       "\n",
       "  DISCHARGE_LOCATION INSURANCE  ... mental misc muscular neoplasms nervous  \\\n",
       "0       DEAD/EXPIRED  Medicare  ...      0    0        0         0       1   \n",
       "\n",
       "  pregnancy  prenatal  respiratory  skin  OUTPUT_LABEL  \n",
       "0         0         0            0     0             1  \n",
       "\n",
       "[1 rows x 34 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train[\"SUBJECT_ID\"]==937]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>DEATHTIME</th>\n",
       "      <th>NEXT_ADMITTIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>937</td>\n",
       "      <td>148592</td>\n",
       "      <td>2163-01-26 08:00:00</td>\n",
       "      <td>2163-01-24 09:29:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>6912</td>\n",
       "      <td>143307</td>\n",
       "      <td>2196-09-09 08:00:00</td>\n",
       "      <td>2196-09-08 11:37:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>9998</td>\n",
       "      <td>144947</td>\n",
       "      <td>2173-06-15 22:00:00</td>\n",
       "      <td>2173-06-14 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>8818</td>\n",
       "      <td>156627</td>\n",
       "      <td>2135-08-19 12:00:00</td>\n",
       "      <td>2135-08-19 14:08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>4791</td>\n",
       "      <td>166578</td>\n",
       "      <td>2157-02-27 05:18:00</td>\n",
       "      <td>2157-02-27 10:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>23843</td>\n",
       "      <td>177112</td>\n",
       "      <td>2144-01-25 23:07:00</td>\n",
       "      <td>2144-01-25 08:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>7880</td>\n",
       "      <td>172698</td>\n",
       "      <td>2165-12-01 08:00:00</td>\n",
       "      <td>2165-12-01 15:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>11740</td>\n",
       "      <td>137487</td>\n",
       "      <td>2154-02-27 08:00:00</td>\n",
       "      <td>2154-02-27 08:43:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>19617</td>\n",
       "      <td>127959</td>\n",
       "      <td>2127-04-04 12:00:00</td>\n",
       "      <td>2127-04-04 15:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>11519</td>\n",
       "      <td>134459</td>\n",
       "      <td>2195-11-28 17:17:00</td>\n",
       "      <td>2195-11-28 15:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>18006</td>\n",
       "      <td>133750</td>\n",
       "      <td>2158-05-16 17:43:00</td>\n",
       "      <td>2158-05-16 19:28:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>24188</td>\n",
       "      <td>140673</td>\n",
       "      <td>2115-06-21 00:10:00</td>\n",
       "      <td>2115-06-21 10:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>14219</td>\n",
       "      <td>171956</td>\n",
       "      <td>2138-05-12 12:00:00</td>\n",
       "      <td>2138-05-12 11:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>28388</td>\n",
       "      <td>179537</td>\n",
       "      <td>2119-11-07 08:00:00</td>\n",
       "      <td>2119-11-07 11:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>18368</td>\n",
       "      <td>194102</td>\n",
       "      <td>2121-02-11 08:00:00</td>\n",
       "      <td>2121-02-10 13:28:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>32637</td>\n",
       "      <td>189200</td>\n",
       "      <td>2160-08-27 08:50:00</td>\n",
       "      <td>2160-08-27 15:27:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SUBJECT_ID  HADM_ID            DEATHTIME       NEXT_ADMITTIME\n",
       "0            937   148592  2163-01-26 08:00:00  2163-01-24 09:29:00\n",
       "507         6912   143307  2196-09-09 08:00:00  2196-09-08 11:37:00\n",
       "552         9998   144947  2173-06-15 22:00:00  2173-06-14 12:00:00\n",
       "579         8818   156627  2135-08-19 12:00:00  2135-08-19 14:08:00\n",
       "722         4791   166578  2157-02-27 05:18:00  2157-02-27 10:59:00\n",
       "846        23843   177112  2144-01-25 23:07:00  2144-01-25 08:40:00\n",
       "1173        7880   172698  2165-12-01 08:00:00  2165-12-01 15:09:00\n",
       "1190       11740   137487  2154-02-27 08:00:00  2154-02-27 08:43:00\n",
       "1217       19617   127959  2127-04-04 12:00:00  2127-04-04 15:07:00\n",
       "1313       11519   134459  2195-11-28 17:17:00  2195-11-28 15:54:00\n",
       "1321       18006   133750  2158-05-16 17:43:00  2158-05-16 19:28:00\n",
       "1433       24188   140673  2115-06-21 00:10:00  2115-06-21 10:04:00\n",
       "1522       14219   171956  2138-05-12 12:00:00  2138-05-12 11:59:00\n",
       "1583       28388   179537  2119-11-07 08:00:00  2119-11-07 11:21:00\n",
       "1661       18368   194102  2121-02-11 08:00:00  2121-02-10 13:28:00\n",
       "1907       32637   189200  2160-08-27 08:50:00  2160-08-27 15:27:00"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[[\"SUBJECT_ID\", \"HADM_ID\", \"DEATHTIME\", \"NEXT_ADMITTIME\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DISCHTIME</th>\n",
       "      <th>DAYS_NEXT_ADMIT</th>\n",
       "      <th>NEXT_ADMITTIME</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>DEATHTIME</th>\n",
       "      <th>DISCHARGE_LOCATION</th>\n",
       "      <th>INSURANCE</th>\n",
       "      <th>...</th>\n",
       "      <th>mental</th>\n",
       "      <th>misc</th>\n",
       "      <th>muscular</th>\n",
       "      <th>neoplasms</th>\n",
       "      <th>nervous</th>\n",
       "      <th>pregnancy</th>\n",
       "      <th>prenatal</th>\n",
       "      <th>respiratory</th>\n",
       "      <th>skin</th>\n",
       "      <th>OUTPUT_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>937</td>\n",
       "      <td>148592</td>\n",
       "      <td>2163-01-20 18:39:00</td>\n",
       "      <td>2163-01-24 08:00:00</td>\n",
       "      <td>0.061806</td>\n",
       "      <td>2163-01-24 09:29:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>2163-01-26 08:00:00</td>\n",
       "      <td>DEAD/EXPIRED</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3016</td>\n",
       "      <td>159142</td>\n",
       "      <td>2107-01-23 02:45:00</td>\n",
       "      <td>2107-01-26 14:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2187</td>\n",
       "      <td>186282</td>\n",
       "      <td>2134-06-24 23:30:00</td>\n",
       "      <td>2134-07-02 17:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REHAB/DISTINCT PART HOSP</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19213</td>\n",
       "      <td>140312</td>\n",
       "      <td>2202-11-02 12:32:00</td>\n",
       "      <td>2202-11-05 14:20:00</td>\n",
       "      <td>12.968056</td>\n",
       "      <td>2202-11-18 13:34:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>425</td>\n",
       "      <td>118058</td>\n",
       "      <td>2149-05-13 12:23:00</td>\n",
       "      <td>2149-05-26 20:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>808</td>\n",
       "      <td>139077</td>\n",
       "      <td>2181-05-11 16:57:00</td>\n",
       "      <td>2181-05-16 11:58:00</td>\n",
       "      <td>13.701389</td>\n",
       "      <td>2181-05-30 04:48:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Private</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>698</td>\n",
       "      <td>171990</td>\n",
       "      <td>2167-12-23 03:24:00</td>\n",
       "      <td>2167-12-31 14:08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNF</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>58821</td>\n",
       "      <td>179166</td>\n",
       "      <td>2176-02-06 21:05:00</td>\n",
       "      <td>2176-02-15 13:39:00</td>\n",
       "      <td>7.473611</td>\n",
       "      <td>2176-02-23 01:01:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNF</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1308</td>\n",
       "      <td>127034</td>\n",
       "      <td>2134-02-21 15:52:00</td>\n",
       "      <td>2134-02-27 14:09:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNF</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>13183</td>\n",
       "      <td>115178</td>\n",
       "      <td>2115-07-20 19:43:00</td>\n",
       "      <td>2115-08-01 17:30:00</td>\n",
       "      <td>23.966667</td>\n",
       "      <td>2115-08-25 16:42:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1990 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SUBJECT_ID  HADM_ID            ADMITTIME            DISCHTIME  \\\n",
       "0            937   148592  2163-01-20 18:39:00  2163-01-24 08:00:00   \n",
       "1           3016   159142  2107-01-23 02:45:00  2107-01-26 14:00:00   \n",
       "2           2187   186282  2134-06-24 23:30:00  2134-07-02 17:45:00   \n",
       "3          19213   140312  2202-11-02 12:32:00  2202-11-05 14:20:00   \n",
       "4            425   118058  2149-05-13 12:23:00  2149-05-26 20:00:00   \n",
       "...          ...      ...                  ...                  ...   \n",
       "1995         808   139077  2181-05-11 16:57:00  2181-05-16 11:58:00   \n",
       "1996         698   171990  2167-12-23 03:24:00  2167-12-31 14:08:00   \n",
       "1997       58821   179166  2176-02-06 21:05:00  2176-02-15 13:39:00   \n",
       "1998        1308   127034  2134-02-21 15:52:00  2134-02-27 14:09:00   \n",
       "1999       13183   115178  2115-07-20 19:43:00  2115-08-01 17:30:00   \n",
       "\n",
       "      DAYS_NEXT_ADMIT       NEXT_ADMITTIME ADMISSION_TYPE  \\\n",
       "0            0.061806  2163-01-24 09:29:00      EMERGENCY   \n",
       "1                 NaN                  NaN      EMERGENCY   \n",
       "2                 NaN                  NaN      EMERGENCY   \n",
       "3           12.968056  2202-11-18 13:34:00      EMERGENCY   \n",
       "4                 NaN                  NaN      EMERGENCY   \n",
       "...               ...                  ...            ...   \n",
       "1995        13.701389  2181-05-30 04:48:00      EMERGENCY   \n",
       "1996              NaN                  NaN      EMERGENCY   \n",
       "1997         7.473611  2176-02-23 01:01:00      EMERGENCY   \n",
       "1998              NaN                  NaN      EMERGENCY   \n",
       "1999        23.966667  2115-08-25 16:42:00      EMERGENCY   \n",
       "\n",
       "                DEATHTIME        DISCHARGE_LOCATION INSURANCE  ... mental  \\\n",
       "0     2163-01-26 08:00:00              DEAD/EXPIRED  Medicare  ...      0   \n",
       "1                     NaN          HOME HEALTH CARE  Medicare  ...      2   \n",
       "2                     NaN  REHAB/DISTINCT PART HOSP  Medicaid  ...      1   \n",
       "3                     NaN                      HOME  Medicare  ...      0   \n",
       "4                     NaN          HOME HEALTH CARE  Medicare  ...      0   \n",
       "...                   ...                       ...       ...  ...    ...   \n",
       "1995                  NaN                      HOME   Private  ...      0   \n",
       "1996                  NaN                       SNF  Medicare  ...      2   \n",
       "1997                  NaN                       SNF  Medicare  ...      0   \n",
       "1998                  NaN                       SNF  Medicare  ...      0   \n",
       "1999                  NaN                      HOME  Medicare  ...      0   \n",
       "\n",
       "     misc muscular neoplasms nervous pregnancy  prenatal  respiratory  skin  \\\n",
       "0       0        0         0       1         0         0            0     0   \n",
       "1       0        0         0       0         0         0            1     0   \n",
       "2       2        1         0       3         0         0            4     0   \n",
       "3       0        0         0       0         0         0            1     1   \n",
       "4       0        0         0       0         0         0            2     1   \n",
       "...   ...      ...       ...     ...       ...       ...          ...   ...   \n",
       "1995    0        0         0       0         0         0            2     0   \n",
       "1996    0        1         0       0         0         0            1     0   \n",
       "1997    0        2         0       0         0         0            0     0   \n",
       "1998    0        0         0       1         0         0            2     0   \n",
       "1999    0        0         1       0         0         0            1     0   \n",
       "\n",
       "      OUTPUT_LABEL  \n",
       "0                1  \n",
       "1                0  \n",
       "2                0  \n",
       "3                1  \n",
       "4                0  \n",
       "...            ...  \n",
       "1995             1  \n",
       "1996             0  \n",
       "1997             1  \n",
       "1998             0  \n",
       "1999             1  \n",
       "\n",
       "[1990 rows x 34 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling\n",
    "\n",
    "### 3.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploring the hyperparameters of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
