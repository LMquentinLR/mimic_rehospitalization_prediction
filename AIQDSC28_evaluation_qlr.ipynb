{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIQDSC28 - Introduction to Deep Learning\n",
    "\n",
    "**Student**: Quentin Le Roux\n",
    "\n",
    "## Instructions\n",
    "\n",
    "With the available part of the MIMICS dataset, **propose your two best models** to predict:\n",
    "\n",
    "> **the number of days to next re-hospitalization** (assessment metrics, MSE on predicted number of days)\n",
    "\n",
    "To build the first model, you can use all or part of the following columns, and of course do all the preprocessing you want:\n",
    "\n",
    "- **DOB**: Date of Birth\n",
    "- **GENDER**\n",
    "- **MARITAL_STATUS**\n",
    "- **ETHNICITY**\n",
    "- **INSURANCE**\n",
    "- **DEATHTIME**: Date of Death (if the patient has died)\n",
    "- **ADMITTIME**: Date of the admission\n",
    "- **ADMISSION_TYPE**\n",
    "    - blood, circulatory, congenital, digestive, endocrine, genitourinary, infectious, injury, mental, misc, muscular, neoplasms, nervous, pregnancy, prenatal, respiratory, skin\n",
    "    - Bag of Words representation of diagnosis\n",
    "- **DISCHTIME**: date of the discharge\n",
    "- **DISCHARGE_LOCATION**: patient's destination after discharge from hospital\n",
    "- **TEXT**: discharge medical report\n",
    "\n",
    "To build the second model, you will add the column TEXT (discharge medical report).\n",
    "\n",
    "To build Y, you can use all or part of the following columns (and there too, do the preprocessing you want):\n",
    "\n",
    "- **DAYS_NEXT_ADMIT**: number of days between discharge and readmission\n",
    "- **NXT_ADMITTIME**: date of readmission\n",
    "- **OUTPUT_LABEL**\n",
    "- **DEATHTIME**: Date of Death (if the patient has died)\n",
    "\n",
    "**Data leakage** (i.e. https://www.kaggle.com/alexisbcook/data-leakage) has to be accounted for/dealt with.\n",
    "\n",
    "The rendering will be in the form of a **jupyter notebook written like a report**: with a clearly announced plan, different sections and a conclusion.\n",
    "\n",
    "*A part of the grade will be given on the quality of the report (8 points), a part on the quality of the work done, and the respect of the methodology (6 points), a part on the quality of the prediction (6 points)*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Note on Data Leakage</span> (excerpts from [Kaggle](https://www.kaggle.com/alexisbcook/data-leakage))\n",
    "\n",
    "> \"Data leakage (or leakage) happens when **your training data contains information about the target**, but similar data will not be available when the model is used for prediction. This leads to high performance on the training set (and possibly even the validation data), but the model will perform poorly in production.\n",
    "> \n",
    "> [...]\n",
    "> \n",
    "> **Target leakage** occurs when your predictors include data that will not be available at the time you make predictions. It is important to think about target leakage in terms of the timing or chronological order that data becomes available, not merely whether a feature helps make good predictions.\n",
    "> \n",
    "> [...] \n",
    "> \n",
    "> Validation is meant to be a measure of how the model does on data that it hasn't considered before. You can corrupt this process in subtle ways if the validation data affects the preprocessing behavior. This is sometimes called **train-test contamination**.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Table of Content\n",
    "\n",
    "1. **Introduction**\n",
    "\n",
    "    a. Overview of project steps\n",
    "    \n",
    "    b. Library imports and built functions\n",
    "\n",
    "\n",
    "2. **Pre-processing**\n",
    "\n",
    "    a. Overview of pre-processing steps\n",
    "    \n",
    "    b. Data pre-processing\n",
    "   \n",
    "   \n",
    "3. **Modeling without the TEXT variable**\n",
    " \n",
    " \n",
    "4. **Modeling with the TEXT variable**\n",
    "\n",
    "\n",
    "5. **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "### 1.1 Overview of project steps\n",
    "    \n",
    "The project will proceed using the following steps:\n",
    "\n",
    "1. **Pre-processing of the dataset** (building a train and test set of features)\n",
    "\n",
    "> We end up with a training and testing set containing 842 features (incl. 819 bag-of-words embedding of the DIAGNOSIS table)\n",
    "\n",
    "> <span style=\"color:red\">TEXT XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX</span>\n",
    "\n",
    "2. **Training and testing our models**\n",
    "\n",
    "\n",
    "3. **Selecting the most promising** of the four and **perform further hyperparameter tuning, dataset refining, etc.** to increase the model's performance\n",
    "\n",
    "\n",
    "4. Perform the same on our TEXT representation\n",
    "\n",
    "\n",
    "5. **Concluding** and propose further areas of exploration\n",
    "\n",
    "\n",
    "### 1.2 Library imports and built functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"ticks\", color_codes=True)\n",
    "\n",
    "from itertools import cycle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Declarations\n",
    "\n",
    "def remove_stop_words(tokenized_sentence):\n",
    "    \"\"\"\n",
    "    Removes the stop words from a tokenized sentence\n",
    "    \"\"\"\n",
    "    punctuation = [\".\", \",\", \"[\", \"]\", \"`\", \"(\", \")\", \n",
    "                   \"?\", \"'\", \"'s\", \":\", \"!\"]\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words += punctuation\n",
    "    return [w for w in tokenized_sentence if w not in stop_words]\n",
    "    \n",
    "def lemmatize(tokenized_sentence):\n",
    "    \"\"\"\n",
    "    Create a lemmatizer object and lematized tokenized items \n",
    "    (e.g. sentences). Might require running the following:\n",
    "        nltk.download('wordnet')\n",
    "    \"\"\"\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(w) for w in tokenized_sentence]\n",
    "\n",
    "sentence_processing = lambda sentence: \" \".join(\n",
    "    lemmatize(\n",
    "        remove_stop_words(\n",
    "            word_tokenize(str.lower(str(sentence)))\n",
    "        )\n",
    "    )\n",
    ")\n",
    "    \n",
    "def regression_score(pred_train, pred_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Prints the MSE and R^2 of a regression model\n",
    "    \"\"\"\n",
    "    mse_train = mean_squared_error(y_train, pred_train)\n",
    "    mse_test = mean_squared_error(y_test, pred_test)\n",
    "    r2_train = r2_score(y_train, pred_train)\n",
    "    r2_test = r2_score(y_test, pred_test)\n",
    "    print(\"--- Train Set Scores ---\")\n",
    "    print('Mean squared error: %.2f' % mse_train)\n",
    "    print('Coefficient of determination: %.2f'% r2_train)\n",
    "    print(\"\\n--- Test Set Scores ---\")\n",
    "    print('Mean squared error: %.2f' % mse_test)\n",
    "    print('Coefficient of determination: %.2f'% r2_test)\n",
    "    return mse_train, mse_test, r2_train, r2_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-processing\n",
    "\n",
    "### 2.1 Overview of pre-processing steps\n",
    "    \n",
    "- Loading the training and testing sets\n",
    "\n",
    "\n",
    "- Providing preliminary notes on the training and testing sets\n",
    "\n",
    "\n",
    "- Identifying columns/features with a risk of data leakage\n",
    "\n",
    "    - issues related to mismatching \"entries for one patient\" in the dataset\n",
    "    \n",
    "    - Data leakage about a potential target variable in some columns\n",
    "\n",
    "\n",
    "- Selecting the feature variables (X)\n",
    "\n",
    "    - Discarding columns due to data leakage\n",
    "    \n",
    "    - Selecting model features\n",
    "    \n",
    "\n",
    "- Building/Wrangling the features variables\n",
    "\n",
    "    - Dealing with NaN values\n",
    "    \n",
    "    - Building a LENGTH_OF_STAY feature\n",
    "    \n",
    "    - Building an AGE feature\n",
    "    \n",
    "    - One-hot encoding the kept discrete features (GENDER, MARITAL_STATUS, ETHNICITY, INSURANCE, ADMISSION_TYPE)\n",
    "    \n",
    "    - Building a word embedding of the DIAGNOSIS column\n",
    "    \n",
    "    - Building the final training and testing datasets\n",
    "\n",
    "\n",
    "- Building the target variable(s) (Y)\n",
    "\n",
    "    - Building a Regression target variable\n",
    "    \n",
    "    - Building a Classification target variable\n",
    "\n",
    "\n",
    "\n",
    "### 2.2 Data Pre-processing\n",
    "\n",
    "#### 1 - <u>Loading the *training* and *testing* sets:</u>\n",
    "\n",
    "We load the dataset and also create placeholder variables. These will hold the processed training and testing data so that we do not erase the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_path = \"http://www.i3s.unice.fr/~riveill/dataset/MIMIC-III-readmission/\"\n",
    "train_set_path = online_path + \"train.csv.zip\"\n",
    "test_set_path = online_path + \"test.csv.zip\"\n",
    "\n",
    "local_train_set_path = \"./datasets/train.csv.zip\"\n",
    "local_test_set_path = \"./datasets/test.csv.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv(train_set_path)\n",
    "# df_train = pd.read_csv(test_set_path)\n",
    "\n",
    "df_train = pd.read_csv(local_train_set_path)\n",
    "df_test = pd.read_csv(local_test_set_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = None\n",
    "X_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = None\n",
    "y_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - <u>Providing preliminary notes on the training and testing sets:</u>\n",
    "\n",
    "- We find that the training dataset holds **2000 entries**, while the testing dataset holds **901 entries**, i.e., a **69 to 31 train-test ratio**. \n",
    "\n",
    "> A small dataset usually implies the following rule of thumb with regards to training: When a dataset is small a ratio of 80 to 20 train-test split is preferable. As such, the current split is okay as-is.\n",
    "\n",
    "\n",
    "- There seems to be **several features with NaN values**. We will have to decide what to do with them.\n",
    "\n",
    "\n",
    "- The available features are of types **int64** or **Object**. We will have to modify the types of those variables accordingly.\n",
    "\n",
    "\n",
    "- As seen in the [MIMIC-III Clinical Database Demo 1.4](https://physionet.org/content/mimiciii-demo/1.4/ADMISSIONS.csv), the DIAGNOSIS variable corresponds to a string value containing a list of diagnoses separated by specific characters (e.g. ' **/** ', ' **;** ', ' **,** ', ' **-** ', etc.). \n",
    "\n",
    "> A bag of words representation of DIAGNOSIS is provided in the dataset. Given that we see more than 0 or 1 values (i.e. binary values), we can infer that the provided BoW approach may represent some kind of importance associated with each word (e.g. number of time the term appears).\n",
    "\n",
    "**Given the lack of information on the way the BoW was created, we might want to create our own word embedding representation**.\n",
    "    \n",
    "<u>Preliminary information on the sets:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>DAYS_NEXT_ADMIT</th>\n",
       "      <th>blood</th>\n",
       "      <th>circulatory</th>\n",
       "      <th>congenital</th>\n",
       "      <th>digestive</th>\n",
       "      <th>endocrine</th>\n",
       "      <th>genitourinary</th>\n",
       "      <th>infectious</th>\n",
       "      <th>...</th>\n",
       "      <th>mental</th>\n",
       "      <th>misc</th>\n",
       "      <th>muscular</th>\n",
       "      <th>neoplasms</th>\n",
       "      <th>nervous</th>\n",
       "      <th>pregnancy</th>\n",
       "      <th>prenatal</th>\n",
       "      <th>respiratory</th>\n",
       "      <th>skin</th>\n",
       "      <th>OUTPUT_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1210.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18155.690500</td>\n",
       "      <td>150103.483000</td>\n",
       "      <td>119.883433</td>\n",
       "      <td>0.482500</td>\n",
       "      <td>2.858000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.747500</td>\n",
       "      <td>1.389000</td>\n",
       "      <td>0.660500</td>\n",
       "      <td>0.438500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447500</td>\n",
       "      <td>0.430500</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.255500</td>\n",
       "      <td>0.421000</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.119000</td>\n",
       "      <td>0.972500</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.5050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>26240.378348</td>\n",
       "      <td>29205.036893</td>\n",
       "      <td>404.753993</td>\n",
       "      <td>0.735503</td>\n",
       "      <td>2.253969</td>\n",
       "      <td>0.196783</td>\n",
       "      <td>1.179593</td>\n",
       "      <td>1.329121</td>\n",
       "      <td>0.895902</td>\n",
       "      <td>0.809658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847114</td>\n",
       "      <td>0.739894</td>\n",
       "      <td>0.544511</td>\n",
       "      <td>0.704605</td>\n",
       "      <td>0.801299</td>\n",
       "      <td>0.151484</td>\n",
       "      <td>0.376709</td>\n",
       "      <td>1.199359</td>\n",
       "      <td>0.551753</td>\n",
       "      <td>0.5001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>100095.000000</td>\n",
       "      <td>-0.602083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1490.500000</td>\n",
       "      <td>124979.500000</td>\n",
       "      <td>5.383333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3103.500000</td>\n",
       "      <td>150743.500000</td>\n",
       "      <td>13.219792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25072.750000</td>\n",
       "      <td>174570.750000</td>\n",
       "      <td>25.327951</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99562.000000</td>\n",
       "      <td>199955.000000</td>\n",
       "      <td>3867.977778</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SUBJECT_ID        HADM_ID  DAYS_NEXT_ADMIT        blood  circulatory  \\\n",
       "count   2000.000000    2000.000000      1210.000000  2000.000000  2000.000000   \n",
       "mean   18155.690500  150103.483000       119.883433     0.482500     2.858000   \n",
       "std    26240.378348   29205.036893       404.753993     0.735503     2.253969   \n",
       "min       11.000000  100095.000000        -0.602083     0.000000     0.000000   \n",
       "25%     1490.500000  124979.500000         5.383333     0.000000     1.000000   \n",
       "50%     3103.500000  150743.500000        13.219792     0.000000     3.000000   \n",
       "75%    25072.750000  174570.750000        25.327951     1.000000     4.000000   \n",
       "max    99562.000000  199955.000000      3867.977778     5.000000    13.000000   \n",
       "\n",
       "        congenital    digestive    endocrine  genitourinary   infectious  ...  \\\n",
       "count  2000.000000  2000.000000  2000.000000    2000.000000  2000.000000  ...   \n",
       "mean      0.036000     0.747500     1.389000       0.660500     0.438500  ...   \n",
       "std       0.196783     1.179593     1.329121       0.895902     0.809658  ...   \n",
       "min       0.000000     0.000000     0.000000       0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000       0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     1.000000       0.000000     0.000000  ...   \n",
       "75%       0.000000     1.000000     2.000000       1.000000     1.000000  ...   \n",
       "max       2.000000     9.000000    10.000000       4.000000     7.000000  ...   \n",
       "\n",
       "            mental         misc     muscular    neoplasms      nervous  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean      0.447500     0.430500     0.216000     0.255500     0.421000   \n",
       "std       0.847114     0.739894     0.544511     0.704605     0.801299   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     1.000000     0.000000     0.000000     1.000000   \n",
       "max       9.000000     5.000000     5.000000     8.000000     7.000000   \n",
       "\n",
       "         pregnancy     prenatal  respiratory         skin  OUTPUT_LABEL  \n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000     2000.0000  \n",
       "mean      0.008000     0.119000     0.972500     0.189000        0.5050  \n",
       "std       0.151484     0.376709     1.199359     0.551753        0.5001  \n",
       "min       0.000000     0.000000     0.000000     0.000000        0.0000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000        0.0000  \n",
       "50%       0.000000     0.000000     1.000000     0.000000        1.0000  \n",
       "75%       0.000000     0.000000     2.000000     0.000000        1.0000  \n",
       "max       4.000000     5.000000     6.000000     6.000000        1.0000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>DAYS_NEXT_ADMIT</th>\n",
       "      <th>blood</th>\n",
       "      <th>circulatory</th>\n",
       "      <th>congenital</th>\n",
       "      <th>digestive</th>\n",
       "      <th>endocrine</th>\n",
       "      <th>genitourinary</th>\n",
       "      <th>infectious</th>\n",
       "      <th>...</th>\n",
       "      <th>mental</th>\n",
       "      <th>misc</th>\n",
       "      <th>muscular</th>\n",
       "      <th>neoplasms</th>\n",
       "      <th>nervous</th>\n",
       "      <th>pregnancy</th>\n",
       "      <th>prenatal</th>\n",
       "      <th>respiratory</th>\n",
       "      <th>skin</th>\n",
       "      <th>OUTPUT_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>526.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>901.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18306.197558</td>\n",
       "      <td>149172.830189</td>\n",
       "      <td>84.578517</td>\n",
       "      <td>0.466149</td>\n",
       "      <td>2.817980</td>\n",
       "      <td>0.044395</td>\n",
       "      <td>0.728080</td>\n",
       "      <td>1.372919</td>\n",
       "      <td>0.700333</td>\n",
       "      <td>0.468368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468368</td>\n",
       "      <td>0.436182</td>\n",
       "      <td>0.201998</td>\n",
       "      <td>0.243063</td>\n",
       "      <td>0.440622</td>\n",
       "      <td>0.015538</td>\n",
       "      <td>0.119867</td>\n",
       "      <td>0.931188</td>\n",
       "      <td>0.241953</td>\n",
       "      <td>0.503885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>26349.689656</td>\n",
       "      <td>29115.501914</td>\n",
       "      <td>304.437951</td>\n",
       "      <td>0.691390</td>\n",
       "      <td>2.256878</td>\n",
       "      <td>0.231479</td>\n",
       "      <td>1.165418</td>\n",
       "      <td>1.406611</td>\n",
       "      <td>0.944628</td>\n",
       "      <td>0.804397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919147</td>\n",
       "      <td>0.752463</td>\n",
       "      <td>0.538760</td>\n",
       "      <td>0.682942</td>\n",
       "      <td>0.784625</td>\n",
       "      <td>0.253383</td>\n",
       "      <td>0.354423</td>\n",
       "      <td>1.184030</td>\n",
       "      <td>0.624726</td>\n",
       "      <td>0.500263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>100039.000000</td>\n",
       "      <td>-0.454167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1521.000000</td>\n",
       "      <td>123423.000000</td>\n",
       "      <td>5.100868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3176.000000</td>\n",
       "      <td>147718.000000</td>\n",
       "      <td>11.302431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25256.000000</td>\n",
       "      <td>174749.000000</td>\n",
       "      <td>22.211632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99982.000000</td>\n",
       "      <td>199807.000000</td>\n",
       "      <td>3543.101389</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SUBJECT_ID        HADM_ID  DAYS_NEXT_ADMIT       blood  circulatory  \\\n",
       "count    901.000000     901.000000       526.000000  901.000000   901.000000   \n",
       "mean   18306.197558  149172.830189        84.578517    0.466149     2.817980   \n",
       "std    26349.689656   29115.501914       304.437951    0.691390     2.256878   \n",
       "min        6.000000  100039.000000        -0.454167    0.000000     0.000000   \n",
       "25%     1521.000000  123423.000000         5.100868    0.000000     1.000000   \n",
       "50%     3176.000000  147718.000000        11.302431    0.000000     2.000000   \n",
       "75%    25256.000000  174749.000000        22.211632    1.000000     4.000000   \n",
       "max    99982.000000  199807.000000      3543.101389    4.000000    12.000000   \n",
       "\n",
       "       congenital   digestive   endocrine  genitourinary  infectious  ...  \\\n",
       "count  901.000000  901.000000  901.000000     901.000000  901.000000  ...   \n",
       "mean     0.044395    0.728080    1.372919       0.700333    0.468368  ...   \n",
       "std      0.231479    1.165418    1.406611       0.944628    0.804397  ...   \n",
       "min      0.000000    0.000000    0.000000       0.000000    0.000000  ...   \n",
       "25%      0.000000    0.000000    0.000000       0.000000    0.000000  ...   \n",
       "50%      0.000000    0.000000    1.000000       0.000000    0.000000  ...   \n",
       "75%      0.000000    1.000000    2.000000       1.000000    1.000000  ...   \n",
       "max      2.000000    7.000000    7.000000       5.000000    7.000000  ...   \n",
       "\n",
       "           mental        misc    muscular   neoplasms     nervous   pregnancy  \\\n",
       "count  901.000000  901.000000  901.000000  901.000000  901.000000  901.000000   \n",
       "mean     0.468368    0.436182    0.201998    0.243063    0.440622    0.015538   \n",
       "std      0.919147    0.752463    0.538760    0.682942    0.784625    0.253383   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      1.000000    1.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "max      6.000000    5.000000    5.000000    5.000000    4.000000    5.000000   \n",
       "\n",
       "         prenatal  respiratory        skin  OUTPUT_LABEL  \n",
       "count  901.000000   901.000000  901.000000    901.000000  \n",
       "mean     0.119867     0.931188    0.241953      0.503885  \n",
       "std      0.354423     1.184030    0.624726      0.500263  \n",
       "min      0.000000     0.000000    0.000000      0.000000  \n",
       "25%      0.000000     0.000000    0.000000      0.000000  \n",
       "50%      0.000000     1.000000    0.000000      1.000000  \n",
       "75%      0.000000     2.000000    0.000000      1.000000  \n",
       "max      3.000000     7.000000    6.000000      1.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 34 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   SUBJECT_ID          2000 non-null   int64  \n",
      " 1   HADM_ID             2000 non-null   int64  \n",
      " 2   ADMITTIME           2000 non-null   object \n",
      " 3   DISCHTIME           2000 non-null   object \n",
      " 4   DAYS_NEXT_ADMIT     1210 non-null   float64\n",
      " 5   NEXT_ADMITTIME      1210 non-null   object \n",
      " 6   ADMISSION_TYPE      2000 non-null   object \n",
      " 7   DEATHTIME           158 non-null    object \n",
      " 8   DISCHARGE_LOCATION  2000 non-null   object \n",
      " 9   INSURANCE           2000 non-null   object \n",
      " 10  MARITAL_STATUS      1924 non-null   object \n",
      " 11  ETHNICITY           2000 non-null   object \n",
      " 12  DIAGNOSIS           1998 non-null   object \n",
      " 13  TEXT                1925 non-null   object \n",
      " 14  GENDER              2000 non-null   object \n",
      " 15  DOB                 2000 non-null   object \n",
      " 16  blood               2000 non-null   int64  \n",
      " 17  circulatory         2000 non-null   int64  \n",
      " 18  congenital          2000 non-null   int64  \n",
      " 19  digestive           2000 non-null   int64  \n",
      " 20  endocrine           2000 non-null   int64  \n",
      " 21  genitourinary       2000 non-null   int64  \n",
      " 22  infectious          2000 non-null   int64  \n",
      " 23  injury              2000 non-null   int64  \n",
      " 24  mental              2000 non-null   int64  \n",
      " 25  misc                2000 non-null   int64  \n",
      " 26  muscular            2000 non-null   int64  \n",
      " 27  neoplasms           2000 non-null   int64  \n",
      " 28  nervous             2000 non-null   int64  \n",
      " 29  pregnancy           2000 non-null   int64  \n",
      " 30  prenatal            2000 non-null   int64  \n",
      " 31  respiratory         2000 non-null   int64  \n",
      " 32  skin                2000 non-null   int64  \n",
      " 33  OUTPUT_LABEL        2000 non-null   int64  \n",
      "dtypes: float64(1), int64(20), object(13)\n",
      "memory usage: 531.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 901 entries, 0 to 900\n",
      "Data columns (total 34 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   SUBJECT_ID          901 non-null    int64  \n",
      " 1   HADM_ID             901 non-null    int64  \n",
      " 2   ADMITTIME           901 non-null    object \n",
      " 3   DISCHTIME           901 non-null    object \n",
      " 4   DAYS_NEXT_ADMIT     526 non-null    float64\n",
      " 5   NEXT_ADMITTIME      526 non-null    object \n",
      " 6   ADMISSION_TYPE      901 non-null    object \n",
      " 7   DEATHTIME           58 non-null     object \n",
      " 8   DISCHARGE_LOCATION  901 non-null    object \n",
      " 9   INSURANCE           901 non-null    object \n",
      " 10  MARITAL_STATUS      861 non-null    object \n",
      " 11  ETHNICITY           901 non-null    object \n",
      " 12  DIAGNOSIS           901 non-null    object \n",
      " 13  TEXT                871 non-null    object \n",
      " 14  GENDER              901 non-null    object \n",
      " 15  DOB                 901 non-null    object \n",
      " 16  blood               901 non-null    int64  \n",
      " 17  circulatory         901 non-null    int64  \n",
      " 18  congenital          901 non-null    int64  \n",
      " 19  digestive           901 non-null    int64  \n",
      " 20  endocrine           901 non-null    int64  \n",
      " 21  genitourinary       901 non-null    int64  \n",
      " 22  infectious          901 non-null    int64  \n",
      " 23  injury              901 non-null    int64  \n",
      " 24  mental              901 non-null    int64  \n",
      " 25  misc                901 non-null    int64  \n",
      " 26  muscular            901 non-null    int64  \n",
      " 27  neoplasms           901 non-null    int64  \n",
      " 28  nervous             901 non-null    int64  \n",
      " 29  pregnancy           901 non-null    int64  \n",
      " 30  prenatal            901 non-null    int64  \n",
      " 31  respiratory         901 non-null    int64  \n",
      " 32  skin                901 non-null    int64  \n",
      " 33  OUTPUT_LABEL        901 non-null    int64  \n",
      "dtypes: float64(1), int64(20), object(13)\n",
      "memory usage: 239.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - <u>Identifying columns/features with a risk of data leakage:</u>\n",
    "\n",
    "> <span style=\"color:red\">The following examples are interesting as they outline data leakage risk we want to contain or remove</span>.\n",
    ">  \n",
    "> Our goal is also individualizing each row so that we reduce the dependencies between each of them. Each datapoint should be independent between each other.\n",
    "\n",
    "1. <u>issues related to mismatching \"entries for one patient\" in the dataset</u>\n",
    "\n",
    "It is possible that a single patient (i.e. a single SUBJECT_ID) has multiple entries in the dataset.\n",
    "\n",
    "> Based on the [information provided by the repository for the MIMIC dataset](https://mimic.physionet.org/mimictables/admissions/), HADM_ID represents a single patient’s admission(s) to the hospital and SUBJECT_ID represents a single patient.\n",
    ">\n",
    "> To avoid data leakage, we must identify features which we will need to exclude due to leakage.\n",
    "\n",
    "<u>Example with SUBJECT_ID 17:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2, 15,  3,  5,  4,  6,  8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We look for the number of times a single patient has been admitted \n",
    "# to a hospital. \n",
    "# We find that a single patient may have been admitted up to 15 times \n",
    "# in the training set.\n",
    "\n",
    "df_train.pivot_table(index = ['SUBJECT_ID'], aggfunc ='size').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBJECT_ID\n",
      "11    1\n",
      "17    2\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DISCHTIME</th>\n",
       "      <th>DAYS_NEXT_ADMIT</th>\n",
       "      <th>NEXT_ADMITTIME</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>DEATHTIME</th>\n",
       "      <th>DISCHARGE_LOCATION</th>\n",
       "      <th>INSURANCE</th>\n",
       "      <th>...</th>\n",
       "      <th>mental</th>\n",
       "      <th>misc</th>\n",
       "      <th>muscular</th>\n",
       "      <th>neoplasms</th>\n",
       "      <th>nervous</th>\n",
       "      <th>pregnancy</th>\n",
       "      <th>prenatal</th>\n",
       "      <th>respiratory</th>\n",
       "      <th>skin</th>\n",
       "      <th>OUTPUT_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>17</td>\n",
       "      <td>161087</td>\n",
       "      <td>2135-05-09 14:11:00</td>\n",
       "      <td>2135-05-13 14:40:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Private</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>17</td>\n",
       "      <td>194023</td>\n",
       "      <td>2134-12-27 07:15:00</td>\n",
       "      <td>2134-12-31 16:05:00</td>\n",
       "      <td>128.920833</td>\n",
       "      <td>2135-05-09 14:11:00</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Private</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SUBJECT_ID  HADM_ID            ADMITTIME            DISCHTIME  \\\n",
       "1182          17   161087  2135-05-09 14:11:00  2135-05-13 14:40:00   \n",
       "1710          17   194023  2134-12-27 07:15:00  2134-12-31 16:05:00   \n",
       "\n",
       "      DAYS_NEXT_ADMIT       NEXT_ADMITTIME ADMISSION_TYPE DEATHTIME  \\\n",
       "1182              NaN                  NaN      EMERGENCY       NaN   \n",
       "1710       128.920833  2135-05-09 14:11:00       ELECTIVE       NaN   \n",
       "\n",
       "     DISCHARGE_LOCATION INSURANCE  ... mental misc muscular neoplasms nervous  \\\n",
       "1182   HOME HEALTH CARE   Private  ...      1    1        2         0       0   \n",
       "1710   HOME HEALTH CARE   Private  ...      0    0        0         0       0   \n",
       "\n",
       "     pregnancy  prenatal  respiratory  skin  OUTPUT_LABEL  \n",
       "1182         0         0            1     0             0  \n",
       "1710         0         0            0     0             0  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We identify that patient 17 has been admitted twice.\n",
    "\n",
    "print(df_train.pivot_table(index = ['SUBJECT_ID'], aggfunc ='size').head(2))\n",
    "df_train[df_train[\"SUBJECT_ID\"]==17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to check if patients have a number of rows equal to the number of admission mentioned in the data (i.e. 1 row = 1 admission). Based on the following data wrangling, it appears that:\n",
    "\n",
    "- Some patients have a mismatched between the number of mentioned readmission dates and the number of lines associated to their case.\n",
    "\n",
    "<u>Interpretation:</u> <span style=\"color:red\">The dataset cannot be understood as a time series</span>. As such, each row (and their potential readmission) should be construed as independent from other rows. \n",
    "\n",
    "<u>Implication:</u> In terms of data leakage, it implies we should individualize each row in a way that no two rows can be linked to each other (independence).\n",
    "\n",
    "<u>Example with SUBJECT_ID 937:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DISCHTIME</th>\n",
       "      <th>DAYS_NEXT_ADMIT</th>\n",
       "      <th>NEXT_ADMITTIME</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>DEATHTIME</th>\n",
       "      <th>DISCHARGE_LOCATION</th>\n",
       "      <th>INSURANCE</th>\n",
       "      <th>...</th>\n",
       "      <th>mental</th>\n",
       "      <th>misc</th>\n",
       "      <th>muscular</th>\n",
       "      <th>neoplasms</th>\n",
       "      <th>nervous</th>\n",
       "      <th>pregnancy</th>\n",
       "      <th>prenatal</th>\n",
       "      <th>respiratory</th>\n",
       "      <th>skin</th>\n",
       "      <th>OUTPUT_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>937</td>\n",
       "      <td>148592</td>\n",
       "      <td>2163-01-20 18:39:00</td>\n",
       "      <td>2163-01-24 08:00:00</td>\n",
       "      <td>0.061806</td>\n",
       "      <td>2163-01-24 09:29:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>2163-01-26 08:00:00</td>\n",
       "      <td>DEAD/EXPIRED</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID  HADM_ID            ADMITTIME            DISCHTIME  \\\n",
       "0         937   148592  2163-01-20 18:39:00  2163-01-24 08:00:00   \n",
       "\n",
       "   DAYS_NEXT_ADMIT       NEXT_ADMITTIME ADMISSION_TYPE            DEATHTIME  \\\n",
       "0         0.061806  2163-01-24 09:29:00      EMERGENCY  2163-01-26 08:00:00   \n",
       "\n",
       "  DISCHARGE_LOCATION INSURANCE  ... mental misc muscular neoplasms nervous  \\\n",
       "0       DEAD/EXPIRED  Medicare  ...      0    0        0         0       1   \n",
       "\n",
       "  pregnancy  prenatal  respiratory  skin  OUTPUT_LABEL  \n",
       "0         0         0            0     0             1  \n",
       "\n",
       "[1 rows x 34 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We find that patient 937 has been admitted twice but has only one \n",
    "# single record in the training dataset.\n",
    "\n",
    "df_train[df_train[\"SUBJECT_ID\"]==937]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Example with SUBJECT_ID 808:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DISCHTIME</th>\n",
       "      <th>DAYS_NEXT_ADMIT</th>\n",
       "      <th>NEXT_ADMITTIME</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>DEATHTIME</th>\n",
       "      <th>DISCHARGE_LOCATION</th>\n",
       "      <th>INSURANCE</th>\n",
       "      <th>...</th>\n",
       "      <th>mental</th>\n",
       "      <th>misc</th>\n",
       "      <th>muscular</th>\n",
       "      <th>neoplasms</th>\n",
       "      <th>nervous</th>\n",
       "      <th>pregnancy</th>\n",
       "      <th>prenatal</th>\n",
       "      <th>respiratory</th>\n",
       "      <th>skin</th>\n",
       "      <th>OUTPUT_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>808</td>\n",
       "      <td>197130</td>\n",
       "      <td>2181-11-16 08:18:00</td>\n",
       "      <td>2181-11-23 09:04:00</td>\n",
       "      <td>8.701389</td>\n",
       "      <td>2181-12-02 01:54:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Private</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>808</td>\n",
       "      <td>100677</td>\n",
       "      <td>2181-07-12 20:11:00</td>\n",
       "      <td>2181-07-17 13:14:00</td>\n",
       "      <td>13.395833</td>\n",
       "      <td>2181-07-30 22:44:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Private</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>808</td>\n",
       "      <td>139077</td>\n",
       "      <td>2181-05-11 16:57:00</td>\n",
       "      <td>2181-05-16 11:58:00</td>\n",
       "      <td>13.701389</td>\n",
       "      <td>2181-05-30 04:48:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Private</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SUBJECT_ID  HADM_ID            ADMITTIME            DISCHTIME  \\\n",
       "553          808   197130  2181-11-16 08:18:00  2181-11-23 09:04:00   \n",
       "1189         808   100677  2181-07-12 20:11:00  2181-07-17 13:14:00   \n",
       "1995         808   139077  2181-05-11 16:57:00  2181-05-16 11:58:00   \n",
       "\n",
       "      DAYS_NEXT_ADMIT       NEXT_ADMITTIME ADMISSION_TYPE DEATHTIME  \\\n",
       "553          8.701389  2181-12-02 01:54:00      EMERGENCY       NaN   \n",
       "1189        13.395833  2181-07-30 22:44:00      EMERGENCY       NaN   \n",
       "1995        13.701389  2181-05-30 04:48:00      EMERGENCY       NaN   \n",
       "\n",
       "     DISCHARGE_LOCATION INSURANCE  ... mental misc muscular neoplasms nervous  \\\n",
       "553    HOME HEALTH CARE   Private  ...      0    0        0         2       0   \n",
       "1189   HOME HEALTH CARE   Private  ...      0    1        0         3       0   \n",
       "1995               HOME   Private  ...      0    0        0         0       0   \n",
       "\n",
       "     pregnancy  prenatal  respiratory  skin  OUTPUT_LABEL  \n",
       "553          0         0            3     0             1  \n",
       "1189         0         0            0     0             1  \n",
       "1995         0         0            2     0             1  \n",
       "\n",
       "[3 rows x 34 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We see that patient 808 has three referenced admissions but the last\n",
    "# record mentions another admission that is not referenced in the set.\n",
    "\n",
    "# The admit times are also mismatched. There are 3 admissions with \n",
    "# each showing a next admission time, implying at least one admission \n",
    "# is missing from the dataset.\n",
    "\n",
    "df_train[df_train[\"SUBJECT_ID\"]==808]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. <u>Data leakage about a potential target variable in some columns</u> \n",
    "    \n",
    "Some features leak information about a potential target variable.\n",
    "\n",
    "We see that DISCHARGE_LOCATION and TEXT hold important data with regards to the outcome of the patient's stay.\n",
    "\n",
    "<u>Example with SUBJECT_ID 937:</u>\n",
    "\n",
    "> In the case of patient 937 (i.e. a 75-year-old man with a history of hypertension), we see that the person died during their care at the hospital and that the mention of their death (term used: dead/expired) is referenced in both columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    DEAD/EXPIRED\n",
       "Name: DISCHARGE_LOCATION, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We find that the cell DISCHARGE_LOCATION holds important data on \n",
    "# the fate of patient 937.\n",
    "\n",
    "df_train[df_train[\"SUBJECT_ID\"]==937][\"DISCHARGE_LOCATION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Admission Date:  [**2163-1-20**]              Discharge Date:   [**2163-1-24**]\\n\\nDate of Birth:  [**2087-9-24**]             Sex:   M\\n\\nService: NEUROLOGY\\n\\nAllergies:\\nPatient recorded as having No Known Allergies to Drugs\\n\\nAttending:[**First Name3 (LF) 5868**]\\nChief Complaint:\\ntransfer from ICH with intra-parenchymal bleed\\n\\nMajor Surgical or Invasive Procedure:\\nnone\\n\\nHistory of Present Illness:\\nThe patient is a 75 year old man with a history of hypertension\\nand high cholesterol, now presenting on transfer from an OSH\\nwith\\na large right intraparenchymal cerebral bleed.  As per his\\nchart, he originally presented to the OSH with the complaint of\\ninability to feel his right leg.  An angiogram of the leg\\nuncovered a right femoral artery occlusion and he was given t-\\nPA (iv).  The next morning, the patient developed a left\\nhemiparesis with left facial droop and a right gaze preference.\\nAn emergent CT scan of his brain showed multiple hemorrhages\\nprimarily in the right frontal lobe, but also including the left\\nparietal lobe and right cerebellum.\\n\\nReview of Systems:\\n-not obtainable\\n\\n\\nPast Medical History:\\n-umbilical hernia repair\\n-gall bladder removal in [**2160**]\\n-hypertension\\n-high cholesterol\\n-aortofemoral + fem-[**Doctor Last Name **] bypass [**2156**]\\n-TURP in [**2152**]\\n\\n\\nSocial History:\\n-no known history of tobacco or alcohol\\n\\n\\nFamily History:\\n-father died at age [**Age over 90 **]\\n-mother died of heart attack\\n\\n\\nPhysical Exam:\\nVitals:  98.6  140/70  54  18  100% intubated\\nGeneral:  elderly man, moving right arm in bed, some distress\\nNeck: supple\\nLungs:  coarse breath sounds\\nCV: regular rate and rhythm, bradycardic\\nAbdomen:  non-tender, non-distended, bowel sounds present\\nExt: warm, no edema\\n\\nNeurologic Examination:\\nNo eye opening to loud voice or sternal rub; not following\\nsimple\\ncommands to squeeze hands or open eyes; pupils minimally\\nreactive\\nto light but equal; no dolls eye movements; left facial droop;\\nspontaneous movement of RUE, RLL, and LLL, no movement of LUE;\\nwithdraws to pain on all extremities except left arm-here he\\nextensor postures; reflexes brisk throughout with no large\\nasymmetries; toe upgoing on left, down on right\\n\\n\\nPertinent Results:\\ncbc:  13.6/20.0/182\\nchem:  135/4.1  102/24  17/0.7  122\\nc/m/p:  8.7/2.2/2.2\\ncoags:  14.7/26.9/1.4\\n\\nHead CT:  multiple discreet areas of hemorrhage, prominent in\\nthe\\nright frontal lobe; intraventricular extension; some edema with\\nmass effect\\n\\n\\nBrief Hospital Course:\\nThe patient was admitted from an OSH for management of a large\\nintra-parenchymal hemmorrhage.  Patient patient had a poor\\nneurologic examination on admission.  The patient continued to\\ndeteriorate and on hospital day #5 was pronounced brain dead.\\nAs per the families wishes, he became an organ donor.\\n\\nMedications on Admission:\\n-nadolol\\n-hctz\\n-lisinopril\\n-zocor\\n-baby asa\\n-mvi\\n-trental\\n\\n\\nDischarge Medications:\\nn/a\\n\\nDischarge Disposition:\\nExpired\\n\\nDischarge Diagnosis:\\n1.  intraparenchymal hemmorrhage\\n\\nDischarge Condition:\\nexpired\\n\\nDischarge Instructions:\\nn/a\\n\\nFollowup Instructions:\\nn/a\\n\\n\\nCompleted by:[**2163-3-14**]']\n"
     ]
    }
   ],
   "source": [
    "# We find that the cell TEXT holds important data on the fate of \n",
    "# patient 937:\n",
    "#     Discharge Disposition:\\nExpired\\n\\nDischarge Diagnosis:\\n1.  \n",
    "#     intraparenchymal hemmorrhage\\n\\nDischarge Condition:\\nexpired\n",
    "\n",
    "print(df_train[df_train[\"SUBJECT_ID\"]==937][\"TEXT\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - <u>Selecting the feature variables (X):</u>\n",
    "\n",
    "1. <u>Discarding columns due to data leakage</u>\n",
    "\n",
    "We decide due to data leakage concerns to not focus on the following variables:\n",
    "\n",
    "- DEATHTIME, ADMITTIME, DISCHTIME: those are obvious data leakage risk as they give information on actual readmission rates\n",
    "- TEXT, DISCHARGE_LOCATION: data leakage risk (see note)\n",
    "- Bag of Words (of DIAGNOSIS): We discard the provided bag of words as we will be building our own embedding\n",
    "\n",
    "2. <u>Selecting model features</u>\n",
    "\n",
    "As such, we focus on the following features (X):\n",
    "\n",
    "- Age (which we will have to construct out of DOB and ADMITTIME)\n",
    "- GENDER\n",
    "- MARITAL_STATUS\n",
    "- ETHNICITY (<span style=\"color:red\">see note</span>)\n",
    "- INSURANCE\n",
    "- ADMISSION_TYPE\n",
    "- Length of stay (which we will have to construct out of DISCTIME and ADMITTIME)\n",
    "- DIAGNOSIS (from which we will build our own bag of words representation)\n",
    "\n",
    "<u><span style=\"color:red\">Note on ETHNICITY</span>:</u>\n",
    "\n",
    "> It is important to note that **ethnic/racial data is a controversial topic in AI**. The goal is to avoid racial profiling as well as racial discrimination. Especially in health. \n",
    ">\n",
    "> It happens that systemic racism and poverty greatly affect minorities in the United States. We recall that the [MIMIC dataset is a relational database containing tables of data relating to patients who stayed within the intensive care units](https://mimic.physionet.org/gettingstarted/overview/) at [Beth Israel Deaconess Medical Center in Boston, MA, USA](https://en.wikipedia.org/wiki/Beth_Israel_Deaconess_Medical_Center). The hospital is a *private* teaching center attached to the Harvard Medical School. In Massachusetts, [poverty afflicts minorities about twice as much as white people](https://www.welfareinfo.org/poverty-rate/massachusetts/).\n",
    ">\n",
    "> As such, ethnicity may have a **strong impact** on both the quality of their care, their access to insurance, and in the end their potential rate of readmission, etc.\n",
    ">\n",
    "> consequently, <span style=\"color:red\">we will need to see if ethnicity has a strong effect on our end result, and, if possible, whether we can do without it</span>.\n",
    "\n",
    "<u><span style=\"color:red\">Note on TEXT and DISCHARGE_LOCATION</span>:</u>\n",
    "\n",
    "> As we saw in the cell above, TEXT and DISCHARGE_LOCATION may hold important information on the end fate of the patient, meaning we cannot include those features as **it would leak information with regards to the outcome we want to predict**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We store our target features (or the columns used to build our \n",
    "# feature, e.g., \"Age\" and \"Length of Stay\") in our placeholders.\n",
    "\n",
    "kept_columns = [\"DOB\", \"GENDER\", \"MARITAL_STATUS\", \"ETHNICITY\", \"INSURANCE\", \n",
    "                \"ADMISSION_TYPE\", \"DIAGNOSIS\", \"ADMITTIME\", \"DISCHTIME\"]\n",
    "\n",
    "X_train = df_train[kept_columns].copy()\n",
    "X_test = df_test[kept_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOB</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>MARITAL_STATUS</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>INSURANCE</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DISCHTIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2087-09-24 00:00:00</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OTHER/UNKNOWN</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>INTRACRANIAL HEMORRHAGE</td>\n",
       "      <td>2163-01-20 18:39:00</td>\n",
       "      <td>2163-01-24 08:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   DOB GENDER MARITAL_STATUS      ETHNICITY INSURANCE  \\\n",
       "0  2087-09-24 00:00:00      M            NaN  OTHER/UNKNOWN  Medicare   \n",
       "\n",
       "  ADMISSION_TYPE                DIAGNOSIS            ADMITTIME  \\\n",
       "0      EMERGENCY  INTRACRANIAL HEMORRHAGE  2163-01-20 18:39:00   \n",
       "\n",
       "             DISCHTIME  \n",
       "0  2163-01-24 08:00:00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 - <u>Building the feature variables (X):</u>\n",
    "\n",
    "1. <u>What about NaN values?</u>\n",
    "\n",
    "> As we see in the first code cell below, NaN values are found only in the MARITAL_STATUS and DIAGNOSIS columns. Knowing we will perform One-Hot Encoding for the former and a Bag of Words Embedding for the latter, we can afford not removing those rows as they will be transformed into features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOB                0\n",
      "GENDER             0\n",
      "MARITAL_STATUS    76\n",
      "ETHNICITY          0\n",
      "INSURANCE          0\n",
      "ADMISSION_TYPE     0\n",
      "DIAGNOSIS          2\n",
      "ADMITTIME          0\n",
      "DISCHTIME          0\n",
      "dtype: int64\n",
      "\n",
      "DOB                0\n",
      "GENDER             0\n",
      "MARITAL_STATUS    40\n",
      "ETHNICITY          0\n",
      "INSURANCE          0\n",
      "ADMISSION_TYPE     0\n",
      "DIAGNOSIS          0\n",
      "ADMITTIME          0\n",
      "DISCHTIME          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# We find that only the columns MARITAL_STATUS and DIAGNOSIS have NaN values in both the training\n",
    "# and testing dataset.\n",
    "\n",
    "print(X_train.isnull().sum(),\n",
    "      X_test.isnull().sum(),\n",
    "      sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. <u>Building LENGTH_OF_STAY (in days)</u>\n",
    "\n",
    "> We build our length of stay variable by taking the difference between ADMITTIME and DISCTIME (in days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LENGTH_OF_STAY\n",
    "\n",
    "# 1. convert dates to datetime\n",
    "# 2. calculate the float value timedelta (in days)\n",
    "X_train[\"ADMITTIME\"] = pd.to_datetime(X_train[\"ADMITTIME\"])\n",
    "X_train[\"DISCHTIME\"] = pd.to_datetime(X_train[\"DISCHTIME\"])\n",
    "X_train[\"LENGTH_OF_STAY\"] = X_train[\"DISCHTIME\"] - X_train[\"ADMITTIME\"]\n",
    "X_train[\"LENGTH_OF_STAY\"] = X_train[\"LENGTH_OF_STAY\"].dt.total_seconds() / (24 * 60 * 60)\n",
    "\n",
    "X_test[\"ADMITTIME\"] = pd.to_datetime(X_test[\"ADMITTIME\"])\n",
    "X_test[\"DISCHTIME\"] = pd.to_datetime(X_test[\"DISCHTIME\"])\n",
    "X_test[\"LENGTH_OF_STAY\"] = X_test[\"DISCHTIME\"] - X_test[\"ADMITTIME\"]\n",
    "X_test[\"LENGTH_OF_STAY\"] = X_test[\"LENGTH_OF_STAY\"].dt.total_seconds() / (24 * 60 * 60)\n",
    "\n",
    " # we drop columns as they are not useful anymore\n",
    "X_train.drop([\"DISCHTIME\"], axis = 1, inplace = True)\n",
    "X_test.drop([\"DISCHTIME\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. <u>Building AGE (in year)</u>\n",
    "\n",
    "> We build our age variable by taking the difference between ADMITTIME and DOB (in year)\n",
    "\n",
    "We see that some ages are impossible (being well above the oldest recorded age for a human being), leading to think that the dataset has misrecorded values. **119 rows are impacted**.\n",
    "\n",
    "The way to deal with those is to **replace these erroneous values with the average age of the rest of the dataset** (i.e. the mean of all ages that are not impossible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGE\n",
    "\n",
    "# 1. convert dates to year\n",
    "# 2. calculate the float value timedelta (in year)\n",
    "X_train[\"DOB\"] = pd.to_datetime(X_train[\"DOB\"]).dt.year\n",
    "X_train[\"ADMITTIME\"] = X_train[\"ADMITTIME\"].dt.year\n",
    "X_train[\"AGE\"] = X_train[\"ADMITTIME\"] - X_train[\"DOB\"]\n",
    "\n",
    "X_test[\"DOB\"] = pd.to_datetime(X_test[\"DOB\"]).dt.year\n",
    "X_test[\"ADMITTIME\"] = X_test[\"ADMITTIME\"].dt.year\n",
    "X_test[\"AGE\"] = X_test[\"ADMITTIME\"] - X_test[\"DOB\"]\n",
    "\n",
    " # we drop columns as they are not useful anymore\n",
    "X_train.drop([\"ADMITTIME\", \"DOB\"], axis = 1, inplace = True)\n",
    "X_test.drop([\"ADMITTIME\", \"DOB\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 300, 301, 302, 303, 305, 306, 307, 308, 310]\n",
      "\n",
      "[0, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 300, 301, 302, 303, 305, 308]\n"
     ]
    }
   ],
   "source": [
    "# Some calculated ages are well above possible values.\n",
    "\n",
    "print(sorted(X_train[\"AGE\"].unique()),\n",
    "      sorted(X_test[\"AGE\"].unique()),\n",
    "      sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 119 age value above 122 (the oldest recorded age in \n",
    "# history in a human)\n",
    "\n",
    "len(X_train[X_train[\"AGE\"]>122])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.22328548644338\n"
     ]
    }
   ],
   "source": [
    "# We calculate the average age of the rest of the train dataset\n",
    "# We replace the wrong age value with the calculated average in \n",
    "# both the train and test dataset\n",
    "\n",
    "average_age = X_train[X_train[\"AGE\"]<=89][\"AGE\"].mean()\n",
    "print(average_age)\n",
    "\n",
    "X_train.loc[(X_train.AGE > 89), 'AGE'] = average_age\n",
    "X_test.loc[(X_test.AGE > 89), 'AGE'] = average_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. <u>One-hot encoding the kept discrete features (GENDER, MARITAL_STATUS, ETHNICITY, INSURANCE, ADMISSION_TYPE)</u>\n",
    "\n",
    "> We build one-hot encoding for those variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot encoding of the following columns:\n",
    "# GENDER, MARITAL_STATUS, ETHNICITY, INSURANCE, ADMISSION_TYPE\n",
    "\n",
    "dummy_list = [\"GENDER\", \"MARITAL_STATUS\", \"ETHNICITY\", \"INSURANCE\", \"ADMISSION_TYPE\"]\n",
    "\n",
    "X_train = pd.get_dummies(X_train, columns = dummy_list)\n",
    "X_test = pd.get_dummies(X_test, columns = dummy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. <u>Building a word embedding of the DIAGNOSIS column</u>\n",
    "\n",
    "> We want to build our own Bag of Word representation using the sklearn CountVectorizer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNOSIS\n",
    "\n",
    "# Pre-processing the content of the DIAGNOSIS column\n",
    "X_train[\"DIAGNOSIS\"] = X_train[\"DIAGNOSIS\"].apply(sentence_processing)\n",
    "X_test[\"DIAGNOSIS\"] = X_test[\"DIAGNOSIS\"].apply(sentence_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying CountVectorizer to the pre-processed DIAGNOSIS column\n",
    "\n",
    "#      We declare and fit the CountVectorizer object\n",
    "cv = CountVectorizer(analyzer=\"word\", ngram_range=(1,1), stop_words=\"english\")\n",
    "cv.fit(X_train[\"DIAGNOSIS\"].tolist())\n",
    "\n",
    "#      We transform the diagnosis column using the count vectorizer\n",
    "tf = lambda s: cv.transform([s]).todense().tolist()[0]\n",
    "X_train[\"DIAGNOSIS\"] = X_train[\"DIAGNOSIS\"].apply(tf)\n",
    "X_test[\"DIAGNOSIS\"] = X_test[\"DIAGNOSIS\"].apply(tf)\n",
    "\n",
    "#      We expand the resulting feature matrix into individual columns\n",
    "X_train[cv.get_feature_names()] = pd.DataFrame(X_train[\"DIAGNOSIS\"].tolist(), \n",
    "                                               index= X_train.index)\n",
    "X_test[cv.get_feature_names()] = pd.DataFrame(X_test[\"DIAGNOSIS\"].tolist(), \n",
    "                                               index= X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of diagnosis features: 819.\n",
      "\n",
      "['1st', '21', '22', 'abcess', 'abd', 'abdcess', 'abdomal', 'abdomen', 'abdominal', 'ablation', 'abscess', 'abuse', 'accending', 'access', 'accident', 'account', 'achalasia', 'acidosis', 'acitic', 'acsites', 'acute', 'advancement', 'afib', 'aicd', 'air', 'airway', 'alcohol', 'als', 'altered', 'aml', 'anasarca', 'anemia', 'aneursym', 'aneurysm', 'angina', 'angio', 'angiogram', 'angioplasty', 'ankle', 'anomaly', 'anterior', 'antibiotic', 'anticholinergic', 'aorta', 'aortic', 'appendicitis', 'approach', 'ar', 'arachnoid', 'arch', 'arf', 'arrest', 'arterial', 'artery', 'ascending', 'ascites', 'aspiration', 'assault', 'asthma', 'asthmaticus', 'ataxia', 'atriacure', 'atrial', 'atrioventricular', 'attach', 'attack', 'aureus', 'av', 'avascular', 'avr', 'axillo', 'bacteremia', 'bacterial', 'benign', 'bental', 'bentall', 'benzodiazepine', 'bi', 'bifemoral', 'bilateral', 'bile', 'bili', 'biliary', 'biventricular', 'bladder', 'bled', 'bleed', 'bleeding', 'block', 'blomyscin', 'blood', 'blunt', 'bone', 'bowel', 'bowl', 'bradycardia', 'brain', 'breast', 'breath', 'bright']\n"
     ]
    }
   ],
   "source": [
    "# We look at the first 100 elements of the feature_names list of the \n",
    "# Count Vectorizer object\n",
    "\n",
    "print(f\"Number of diagnosis features: {len(cv.get_feature_names())}.\",\n",
    "      cv.get_feature_names()[:100],\n",
    "      sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. <u>Building the final training and testing datasets</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop the DIAGNOSIS column\n",
    "X_train.drop([\"DIAGNOSIS\"], axis=1, inplace=True)\n",
    "X_test.drop([\"DIAGNOSIS\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LENGTH_OF_STAY</th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER_F</th>\n",
       "      <th>GENDER_M</th>\n",
       "      <th>MARITAL_STATUS_DIVORCED</th>\n",
       "      <th>MARITAL_STATUS_MARRIED</th>\n",
       "      <th>MARITAL_STATUS_SEPARATED</th>\n",
       "      <th>MARITAL_STATUS_SINGLE</th>\n",
       "      <th>MARITAL_STATUS_UNKNOWN (DEFAULT)</th>\n",
       "      <th>MARITAL_STATUS_WIDOWED</th>\n",
       "      <th>...</th>\n",
       "      <th>wbc</th>\n",
       "      <th>weakness</th>\n",
       "      <th>west</th>\n",
       "      <th>wide</th>\n",
       "      <th>withdrawal</th>\n",
       "      <th>withdrawl</th>\n",
       "      <th>work</th>\n",
       "      <th>worsening</th>\n",
       "      <th>wound</th>\n",
       "      <th>wrist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.55625</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 842 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LENGTH_OF_STAY   AGE  GENDER_F  GENDER_M  MARITAL_STATUS_DIVORCED  \\\n",
       "0         3.55625  76.0         0         1                        0   \n",
       "\n",
       "   MARITAL_STATUS_MARRIED  MARITAL_STATUS_SEPARATED  MARITAL_STATUS_SINGLE  \\\n",
       "0                       0                         0                      0   \n",
       "\n",
       "   MARITAL_STATUS_UNKNOWN (DEFAULT)  MARITAL_STATUS_WIDOWED  ...  wbc  \\\n",
       "0                                 0                       0  ...    0   \n",
       "\n",
       "   weakness  west  wide  withdrawal  withdrawl  work  worsening  wound  wrist  \n",
       "0         0     0     0           0          0     0          0      0      0  \n",
       "\n",
       "[1 rows x 842 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LENGTH_OF_STAY</th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER_F</th>\n",
       "      <th>GENDER_M</th>\n",
       "      <th>MARITAL_STATUS_DIVORCED</th>\n",
       "      <th>MARITAL_STATUS_MARRIED</th>\n",
       "      <th>MARITAL_STATUS_SEPARATED</th>\n",
       "      <th>MARITAL_STATUS_SINGLE</th>\n",
       "      <th>MARITAL_STATUS_UNKNOWN (DEFAULT)</th>\n",
       "      <th>MARITAL_STATUS_WIDOWED</th>\n",
       "      <th>...</th>\n",
       "      <th>wbc</th>\n",
       "      <th>weakness</th>\n",
       "      <th>west</th>\n",
       "      <th>wide</th>\n",
       "      <th>withdrawal</th>\n",
       "      <th>withdrawl</th>\n",
       "      <th>work</th>\n",
       "      <th>worsening</th>\n",
       "      <th>wound</th>\n",
       "      <th>wrist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.55</td>\n",
       "      <td>62.223285</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 842 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LENGTH_OF_STAY        AGE  GENDER_F  GENDER_M  MARITAL_STATUS_DIVORCED  \\\n",
       "0           39.55  62.223285         0         1                        0   \n",
       "\n",
       "   MARITAL_STATUS_MARRIED  MARITAL_STATUS_SEPARATED  MARITAL_STATUS_SINGLE  \\\n",
       "0                       0                         0                      0   \n",
       "\n",
       "   MARITAL_STATUS_UNKNOWN (DEFAULT)  MARITAL_STATUS_WIDOWED  ...  wbc  \\\n",
       "0                                 0                       0  ...    0   \n",
       "\n",
       "   weakness  west  wide  withdrawal  withdrawl  work  worsening  wound  wrist  \n",
       "0         0     0     0           0          0     0          0      0      0  \n",
       "\n",
       "[1 rows x 842 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6 - <u>Building the target variable (Y):</u>\n",
    "    \n",
    "We want to estimate the re-hospitalization rate of a patient. The question is then:\n",
    "\n",
    "> how to represent re-hospitalization?\n",
    "\n",
    "In the case of **Regression**, we can predict the number of days between discharge and readmission for a patient\n",
    "\n",
    "> We can build this target variable by using the DAYS_NEXT_ADMIT column. The issue is about how to represent the absence of readmission (NaN in the dataset)\n",
    ">\n",
    "> <u>Assumptions:</u>\n",
    ">\n",
    "> 1. Since there is no 0-valued DAYS_NEXT_ADMIT item in the dataset, we decide to set NaN values in that column to 0\n",
    "\n",
    "<u>Building our regression-style target variable</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790\n",
      "375\n"
     ]
    }
   ],
   "source": [
    "# We record the DAYS_NEXT_ADMIT column\n",
    "\n",
    "y_train = df_train[\"DAYS_NEXT_ADMIT\"].copy()\n",
    "y_test = df_test[\"DAYS_NEXT_ADMIT\"].copy()\n",
    "\n",
    "# We count the NaN values\n",
    "\n",
    "print(y_train.isnull().sum(),\n",
    "      y_test.isnull().sum(),\n",
    "      sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Based on our regression assumption we set NaN values to 0\n",
    "\n",
    "y_train[y_train.isnull()]=0\n",
    "y_test[y_test.isnull()]=0\n",
    "\n",
    "# We check the NaN values have been changed\n",
    "\n",
    "print(y_train.isnull().sum(),\n",
    "      y_test.isnull().sum(),\n",
    "      sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling without the TEXT variable\n",
    "\n",
    "<u>Approach for Regression-style modeling:</u>\n",
    "\n",
    "To evaluate our Linear Regression model, we will be using the Mean Squared Error and Coefficient of Determination $R^2$.\n",
    "\n",
    "$${MSE} = \\frac{1}{n}\\overset{n}{\\underset{i=1}{\\sum}}(Y_i - \\hat{Y}_i)^2$$\n",
    "\n",
    "With $Y$ the vector of observed values of the variable being predicted, $\\hat{Y}$ the predicted values.\n",
    "\n",
    "$$R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}$$\n",
    "\n",
    "with $SS_{tot}$, the total sum of squares (and $\\bar{y} = \\frac{1}{n}\\overset{n}{\\underset{i=1}{\\sum}}Y_i$):\n",
    "\n",
    "$$SS_{tot} = \\overset{n}{\\underset{i=1}{\\sum}}(Y_i - \\bar{Y})$$\n",
    "\n",
    "And with $SS_{res}$, the sum of squares of residuals, i.e., $MSE$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model declaration and training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.XXXXXXXXXXXXXXXXXX Observations\n",
    "\n",
    "<span style=\"color:green\">qqqqq.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling with the TEXT variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model declaration and training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.XXXXXXXXXXXXXXXXXX Observations\n",
    "\n",
    "<span style=\"color:green\">qqqqq.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
